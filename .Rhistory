pwc_B <- pwc_B %>% rstatix::add_xy_position(x = "COND", fun = "mean_se")
ggpubr::ggline(get_emmeans(pwc_B), x = "COND", y = "emmean") +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
stat_pvalue_manual(pwc_B, hide.ns = TRUE, tip.length = FALSE) +
labs(
subtitle = rstatix::get_test_label(MurrarB_ANCOVA, detailed = TRUE),
caption = rstatix::get_pwc_label(pwc_B)
)
pwc_B <- pwc_B %>% rstatix::add_xy_position(x = "COND", fun = "mean_se")
ggpubr::ggline(rstatix::get_emmeans(pwc_B), x = "COND", y = "emmean") +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
stat_pvalue_manual(pwc_B, hide.ns = TRUE, tip.length = FALSE) +
labs(
subtitle = rstatix::get_test_label(MurrarB_ANCOVA, detailed = TRUE),
caption = rstatix::get_pwc_label(pwc_B)
)
pwc_B <- pwc_B %>% rstatix::add_xy_position(x = "COND", fun = "mean_se")
ggpubr::ggline(rstatix::get_emmeans(pwc_B), x = "COND", y = "emmean") +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
ggpubr::stat_pvalue_manual(pwc_B, hide.ns = TRUE, tip.length = FALSE) +
labs(
subtitle = rstatix::get_test_label(MurrarB_ANCOVA, detailed = TRUE),
caption = rstatix::get_pwc_label(pwc_B)
)
ggpubr::ggscatter (
Murrar_wide, x = "AttWhiteP1", y = "AttArabP1",
color = "COND", add = "reg.line"
)+
stat_regline_equation(
aes(label =  paste(..eq.label.., ..rr.label.., sep = "~~~~"), color = COND)
)
ggpubr::ggscatter (
Murrar_wide, x = "AttWhiteP1", y = "AttArabP1",
color = "COND", add = "reg.line"
)+
ggpubr::stat_regline_equation(
aes(label =  paste(..eq.label.., ..rr.label.., sep = "~~~~"), color = COND)
)
Murrar_wide %>% rstatix::anova_test(AttArabP1 ~ COND*AttWhiteP1)
WhCov_mod <- lm (AttArabP1 ~ AttWhiteP1 + COND, data = Murrar_wide) #Create a linear regression model predicting DV from COV & IV
WhCov_mod
WhCov_mod.metrics <- broom::augment(WhCov_mod)
head(WhCov_mod.metrics,3) #shows the first three rows of the UEcon_model.metrics
shapiro_test(WhCov_mod.metrics$.resid)
rstatix::shapiro_test(WhCov_mod.metrics$.resid)
rstatix::shapiro_test(WhCov_mod.metrics$.resid)
WhCov_mod.metrics %>% rstatix::levene_test(.resid ~ COND)
WhCov_mod.metrics %>%
filter(abs(.std.resid)>3)%>%
as.data.frame()
WhCov_ANCOVA <- Murrar_wide %>%
anova_test(AttArabP1 ~ AttWhiteP1 + COND)
WhCov_ANCOVA <- Murrar_wide %>%
rstatix::anova_test(AttArabP1 ~ AttWhiteP1 + COND)
get_anova_table(WhCov_ANCOVA)
WhCov_ANCOVA <- Murrar_wide %>%
rstatix::anova_test(AttArabP1 ~ AttWhiteP1 + COND)
rstatix::get_anova_table(WhCov_ANCOVA)
pwc_cond <- Murrar_wide %>%
rstatix::emmeans_test(
AttArabP1 ~ COND, covariate = AttWhiteP1,
p.adjust.method = "none"
)
pwc_cond
emmeans_cond <- get_emmeans(pwc_cond)
emmeans_cond <- rstatix::get_emmeans(pwc_cond)
emmeans_cond
descripts_cond <- psych::describeBy(AttArabP1 ~ COND, data = Murrar_wide, mat = TRUE)
descripts_cond
apaTables::apa.cor.table(Murrar_wide[c("AttArabP1", "AttWhiteP1")], table.number = 2 )
#You can save this as a Microsoft word document by adding this statement into the command: filename = "your_filename.doc"
MASS::write.matrix(pwc_cond, sep = ",", file = "pwc_con.csv")
MASS::write.matrix(emmeans_cond, sep = ",", file = "emmeans_con.csv")
MASS::write.matrix(descripts_cond, sep = ",", file = "descripts_con.csv")
pwc_cond <- pwc_cond %>% rstatix::add_xy_position(x = "COND", fun = "mean_se")
ggpubr::ggline(rstatix::get_emmeans(pwc_B), x = "COND", y = "emmean") +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
rstatix::stat_pvalue_manual(pwc_B, hide.ns = TRUE, tip.length = FALSE) +
labs(
subtitle = rstatix::get_test_label(WhCov_ANCOVA, detailed = TRUE),
caption = rstatix::get_pwc_label(pwc_cond)
)
pwc_cond <- pwc_cond %>% rstatix::add_xy_position(x = "COND", fun = "mean_se")
ggpubr::ggline(rstatix::get_emmeans(pwc_B), x = "COND", y = "emmean") +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
ggpubr::stat_pvalue_manual(pwc_B, hide.ns = TRUE, tip.length = FALSE) +
labs(
subtitle = rstatix::get_test_label(WhCov_ANCOVA, detailed = TRUE),
caption = rstatix::get_pwc_label(pwc_cond)
)
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen=999)#eliminates scientific notation
#will install the package if not already installed
#if(!require(tidyverse)){install.packages("tidyverse")}
#if(!require(psych)){install.packages("psych")}
#if(!require(apaTables)){install.packages("apaTables")}
#if(!require(MASS)){install.packages("MASS")}
set.seed(210807)#sets the random seed so that we consistently get the same results
#for practice, you could change (or remove) the random seed and try to interpret the results (they should be quite similar)
#There are probably more efficient ways to simulate data. Given the information available in the manuscript, my approach was to first create the datasets for each of the racial ethnic groups that were provided and then binding them together.
#First, the data for the students who identified as Asian American
Asian_mu <- c(1.52, 1.72, 2.69, 1.71, 2.14, 2.35, 2.42)
Asian_stddev <- c(2.52, 2.04, 0.47, 0.70, 0.80, 2.41, 3.36)
Asian_corMat <- matrix(c(1.00, 0.69, 0.19, 0.28, 0.32,  0.08,  0.23,
0.69,  1.00,  0.20,  0.29,  0.33,  0.13,  0.25,
0.19,  0.20,  1.00,  0.50,  0.50, -0.04,  0.09,
0.28,  0.29,  0.50,  1.00,  0.76,  0.04,  0.18,
0.32,  0.33,  0.50,  0.76,  1.00,  0.10,  0.21,
0.08,  0.13, -0.04,  0.04,  0.10,  1.00,  0.42,
0.23,  0.25,  0.09,  0.18,  0.21,  0.42,  1.00),
ncol=7)
Asian_covMat <- Asian_stddev %*% t(Asian_stddev) * Asian_corMat
Asian_dat <- MASS::mvrnorm(n = 398, mu = Asian_mu, Sigma = Asian_covMat, empirical = TRUE)
Asian_df <- as.data.frame(Asian_dat)
library(tidyverse)
Asian_df <- rename(Asian_df, OvDisc = V1, mAggr = V2, Neuro = V3, nAff = V4, psyDist = V5, Alcohol = V6, drProb = V7)
Asian_df$RacEth <- "Asian"
#Second, the data for the students who identified as Black/African American
Black_mu <- c(4.45, 3.84, 2.60, 1.84, 2.10, 2.81, 2.14)
Black_stddev <- c(4.22, 3.08, 0.89, 0.80, 0.81, 2.49, 3.24)
Black_corMat <- matrix(c( 1.00,  0.81,  0.17,  0.15,  0.09,  0.05, -0.16,
0.81,  1.00,  0.17,  0.21,  0.11,  0.09, -0.01,
0.17,  0.17,  1.00,  0.59,  0.54,  0.05,  0.24,
0.15,  0.21,  0.59,  1.00,  0.72,  0.12,  0.22,
0.09,  0.11,  0.54,  0.72,  1.00,  0.21,  0.40,
0.05,  0.09,  0.05,  0.12,  0.21,  1.00,  0.65,
-0.16,-0.01,  0.24,  0.22,  0.40,  0.65,  1.00),
ncol = 7)
Black_covMat <- Black_stddev %*% t(Black_stddev) * Black_corMat
Black_dat <- MASS::mvrnorm(n = 133, mu = Black_mu, Sigma = Black_covMat, empirical = TRUE)
Black_df <- as.data.frame(Black_dat)
Black_df <- rename(Black_df, OvDisc = V1, mAggr = V2, Neuro = V3, nAff = V4, psyDist = V5, Alcohol = V6, drProb = V7)
Black_df$RacEth <- "Black"
#Third, the data for the students who identified as Latinx American
Latinx_mu <- c(1.56, 2.34, 2.69, 1.81, 2.17, 3.47, 2.69)
Latinx_stddev <- c(2.46, 2.49, 0.86, 0.71, 0.78, 2.59, 3.76)
Latinx_corMat <- matrix(c( 1.00,  0.78,  0.27,  0.36,  0.42, -0.06,  0.08,
0.78,  1.00,  0.33,  0.26,  0.35, -0.11, -0.02,
0.27,  0.33,  1.00,  0.62,  0.64, -0.04,  0.15,
0.36,  0.26,  0.62,  1.00,  0.81, -0.08,  0.17,
0.42,  0.35,  0.64,  0.81,  1.00, -0.06,  0.15,
-0.06,-0.11, -0.04, -0.08, -0.06,  1.00,  0.60,
0.08, -0.02,  0.15,  0.17,  0.15,  0.60,  1.00),
ncol = 7)
Latinx_covMat <- Latinx_stddev %*% t(Latinx_stddev) * Latinx_corMat
Latinx_dat <- MASS::mvrnorm(n = 182, mu = Latinx_mu, Sigma = Latinx_covMat, empirical = TRUE)
Latinx_df <- as.data.frame(Latinx_dat)
Latinx_df <- rename(Latinx_df, OvDisc = V1, mAggr = V2, Neuro = V3, nAff = V4, psyDist = V5, Alcohol = V6, drProb = V7)
Latinx_df$RacEth <- "Latinx"
Lui_sim_df <-bind_rows (Asian_df, Black_df, Latinx_df)
#write the simulated data as a .csv
#write.table(Lui_sim_df, file="Lui_CSV.csv", sep=",", col.names=TRUE, row.names=FALSE)
#bring back the simulated dat from a .csv file
#df <- read.csv ("Lui_CSV.csv", header = TRUE)
#to save the df as an .rds (think "R object") file on your computer; it should save in the same file as the .rmd file you are working with
#saveRDS(Lui_sim_df, "Lui_RDS.rds")
#bring back the simulated dat from an .rds file
#df <- readRDS("Lui_RDS.rds")
df <- Lui_sim_df
str (df)
# A .csv file is uninformed -- it just holds data (and R guesses what it is); respecifying the type of variable will likely need to be completed each time the file is used.
df <- df %>%
dplyr::mutate(
RacEth = as.factor(RacEth))
#checking the structure of the data
str(df)
library(tidyverse) #I often "open" the package by placing it (and two colons) in front of its function. However, opening tidyverse via the library command allows me to use the pipe: %>%
tiny_df <- df%>%
dplyr::select(mAggr, nAff, psyDist)
psych::describe(tiny_df)
psych::describeBy (df, df$RacEth)
#, mat=TRUE
psych::describeBy (df, df$RacEth, mat=TRUE)
#, mat=TRUE
#Note, this script results in a different simulation than is in the ReadySetR lesson
set.seed(210820) #sets a random seed so that we get the same results each time
Accurate <- c(rnorm(30, mean=1.18, sd=0.80), rnorm(30, mean=1.83, sd = 0.58), rnorm(30, mean = 1.76, sd = 0.56))#sample size, M and SD for each group
Accurate[Accurate>3]<-3 #set upper bound for DV
Accurate[Accurate<0]<-0 #set lower bound for DV
moreTalk <- c(rnorm(30, mean=-.82, sd=0.91), rnorm(30, mean=-0.39, sd = 0.66), rnorm(30, mean = -0.04, sd = 0.71))#sample size, M and SD for each group
moreTalk[moreTalk>2]<- 2 #set upper bound for DV
moreTalk[moreTalk<-2]<- -2 #set lower bound for DV
ID<-factor(seq(1,90)) #IDs for participants
COND<-c(rep("High", 30), rep("Low", 30), rep("Control", 30)) #name factors and identify how many in each group; should be in same order as first row of script
accSIM30 <-data.frame(ID, COND, Accurate, moreTalk) #groups the 3 variables into a single df:  ID#, DV, condition
#only have to run this ONCE to draw from the same Qualtrics account...but will need to get diff
library(qualtRics)
qualtrics_api_credentials(api_key = "Q65NIelIWsnSBw0uUIJtKIm3oYmxBbWxgP6apCT9",
base_url = "spupsych.az1.qualtrics.com", overwrite = TRUE, install = TRUE)
readRenviron("~/.Renviron")
#only have to run this ONCE to draw from the same Qualtrics account...but will need to get diff
library(qualtRics)
qualtrics_api_credentials(api_key = "Q65NIelIWsnSBw0uUIJtKIm3oYmxBbWxgP6apCT9",
base_url = "spupsych.az1.qualtrics.com", overwrite = TRUE, install = TRUE)
readRenviron("~/.Renviron")
readRenviron("~/.Renviron")
df <-qualtRics::fetch_survey(surveyID = "SV_6zEqY4i6p8rGJz7", time_zone = NULL, verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
View(df)
library(data.table)
str(df$EndDate)
unclass(df$EndDate)
str(df$EndDate)
#This is where to put the code that gets rid of post data from May 2
library(data.table)
setDT(df)[order(Key_4, -as.IDate(Date, "%Y-%m-%dT%H:%M")), head(.SD, 1), by =Key_4]
#This is where to put the code that gets rid of post data from May 2
library(data.table)
setDT(df)[order(Key_4, -as.IDate(EndDate, "%Y-%m-%dT%H:%M")), head(.SD, 1), by =Key_4]
#This is where to put the code that gets rid of post data from May 2
library(data.table)
lessdupes <- setDT(df)[order(Key_4, -as.IDate(EndDate, "%Y-%m-%dT%H:%M")), head(.SD, 1), by =Key_4]
View(lessdupes)
df <- df%>%
group_by(Keu_4)%>%
mutate(index = order(order(EndDate, decreasing = FALSE)))
library(tidyverse)
lessdupes <- df%>%
group_by(Key_4)%>%
mutate(index = order(order(EndDate, decreasing = FALSE)))
View(lessdupes)
df$ID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3"")
df$ID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3)
df <- toupper(df$Key_2)
df$ID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3)
#will install the package if not already installed
#if(!require(qualtRics)){install.packages("qualtRics")}
#if(!require(tidyverse)){install.packages("tidyverse")}
#only have to run this ONCE to draw from the same Qualtrics account...but will need to get diff
library(qualtRics)
qualtrics_api_credentials(api_key = "Q65NIelIWsnSBw0uUIJtKIm3oYmxBbWxgP6apCT9",
base_url = "spupsych.az1.qualtrics.com", overwrite = TRUE, install = TRUE)
readRenviron("~/.Renviron")
#QTRX_csv <- read_survey("KCSARC_VPS220323.csv", strip_html = TRUE, import_id = FALSE, time_zone = FALSE
#surveys <- all_surveys()
#surveys
df <-qualtRics::fetch_survey(surveyID = "SV_6zEqY4i6p8rGJz7", time_zone = NULL, verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
str(df$EndDate)
unclass(df$EndDate)
df <- mutate(df$Key_2, funs=toupper)
str(df$Key_2)
View(df)
df$ID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3)
lessdupes <- df%>%
group_by(ID)%>%
mutate(index = order(order(EndDate, decreasing = FALSE)))
View(lessdupes)
View(lessdupes)
lessdupes <-(select (lessdupes, ID, index, EndDate, everything()))
View(lessdupes)
lessdupes$index <- ifelse(lessdupes$ID == "NA-NA-NA", NA, lessdupes$ID)
str(df$Key_2)
library(tidyverse)
df$ID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3)
lessdupes <- df%>%
group_by(ID)%>%
mutate(index = order(order(EndDate, decreasing = FALSE)))
lessdupes <-(select (lessdupes, ID, index, EndDate, everything()))
lessdupes$index <- ifelse(lessdupes$ID == "NA-NA-NA", NA, lessdupes$index)
lessdupes$index <- ifelse(lessdupes$ID == "NA - NA - NA", NA, lessdupes$index)
lessdupes <- df[!(df$index =="2"),]
str(df$Key_2)
library(tidyverse)
df$ID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3)
df <- df%>%
group_by(ID)%>%
mutate(index = order(order(EndDate, decreasing = FALSE)))
df <-(select (df, ID, index, EndDate, everything()))
df$index <- ifelse(df$ID == "NA - NA - NA", NA, df$index)
lessdupes <- df[!(df$index =="2"),]
View(lessdupes)
df$Key_2b <- toupper(df1$Key_2)
df$Key_2b <- toupper(df$Key_2)
```{r}
str(df$Key_2)
library(tidyverse)
df$ID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3)
df <- df%>%
group_by(ID)%>%
mutate(index = order(order(EndDate, decreasing = FALSE)))
df <-(select (df, ID, index, EndDate, everything()))
df$Key_2 <- toupper(df$Key_2)
df <-qualtRics::fetch_survey(surveyID = "SV_6zEqY4i6p8rGJz7", time_zone = NULL, verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
str(df$EndDate)
unclass(df$EndDate)
str(df$Key_2)
library(tidyverse)
df$Key_2 <- toupper(df$Key_2)
df$ID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3)
df <- df%>%
group_by(ID)%>%
mutate(index = order(order(EndDate, decreasing = FALSE)))
df <-(select (df, ID, index, EndDate, everything()))
df$index <- ifelse(df$ID == "NA - NA - NA", NA, df$index)
lessdupes <- df[!(df$index =="2"),]
#this less us properly delete the students who took it a second time (it saved us one student)
df <- df[!(df$index =="2"),]
df <-qualtRics::fetch_survey(surveyID = "SV_6zEqY4i6p8rGJz7", time_zone = NULL, verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
str(df$EndDate)
unclass(df$EndDate)
library(tidyverse)
#the identification key was three parts; the second used letters from their name
#the students were using a mix of upper and lowercase; this makes it all upper case (otherwise R would read them as different people).
#this code makes the second part of the identification key all upper case
df$Key_2 <- toupper(df$Key_2)
#this combines the three parts of the key
df$ID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3)
#this assigns an index number (time1, time2, etc.) by the ID
df <- df%>%
group_by(ID)%>%
mutate(index = order(order(EndDate, decreasing = FALSE)))
#this puts those variables we care about all at the front so we can check our work
#for your project I want to get rid of all those with a number 2,
#unfortunately, the students who took this survey all before we had the key/identification system all have NAs,
#so first I have to recode those kids with NA as NA before I can delete the "2s"
df <-(select (df, ID, index, EndDate, everything()))
#this code recodes all the students with an ID of NA - NA - NA as NA
df$index <- ifelse(df$ID == "NA - NA - NA", NA, df$index)
#this less us properly delete the students who took it a second time (it saved us one student)
df <- df[!(df$index =="2"),]
dev.set(dev.next())
library(tidyverse)
df %>%
count(Gender)
df$gender <- factor(df$Gender,
levels = c("1","2", "3"),
labels = c("Male", "Female", "Other"))
str(df$gender)
library(sjstats)
Emp_vars <- c('emp1_1','emp1_2','emp1_3','emp1_4','emp2_1','emp2_2','emp2_3','emp2_4','emp2_5')
df$Empathy <- sjstats::mean_n(df[,Emp_vars], .80)
Con_vars <- c('consent_1','consent_2','consent_3','consent_4','consent_5','consent_6')
df$Consent <- sjstats::mean_n(df[,Con_vars], .80)
Mgrs_vars<- c('mgrs_1','mgrs_2','mgrs_3','mgrs_5','mgrs_7')
df$MGRS <- sjstats::mean_n(df[,Mgrs_vars], .80)
EMPdf <- df%>%dplyr::select(emp1_1:emp2_5)
psych::alpha(EMPdf)
df <-qualtRics::fetch_survey(surveyID = "SV_6zEqY4i6p8rGJz7", time_zone = NULL, verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
library(tidyverse)
#the identification key was three parts; the second used letters from their name
#the students were using a mix of upper and lowercase; this makes it all upper case (otherwise R would read them as different people).
#this code makes the second part of the identification key all upper case
df$Key_2 <- toupper(df$Key_2)
#this combines the three parts of the key
df$ID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3)
#this assigns an index number (time1, time2, etc.) by the ID
df <- df%>%
group_by(ID)%>%
mutate(index = order(order(EndDate, decreasing = FALSE)))
#this puts those variables we care about all at the front so we can check our work
#for your project I want to get rid of all those with a number 2,
#unfortunately, the students who took this survey all before we had the key/identification system all have NAs,
#so first I have to recode those kids with NA as NA before I can delete the "2s"
df <-(select (df, ID, index, EndDate, everything()))
#this code recodes all the students with an ID of NA - NA - NA as NA
df$index <- ifelse(df$ID == "NA - NA - NA", NA, df$index)
#this less us properly delete the students who took it a second time (it saved us one student)
df <- df[!(df$index =="2"),]
library(tidyverse)
df %>%
count(Gender)
df$gender <- factor(df$Gender,
levels = c("1","2", "3"),
labels = c("Male", "Female", "Other"))
str(df$gender)
library(sjstats)
Emp_vars <- c('emp1_1','emp1_2','emp1_3','emp1_4','emp2_1','emp2_2','emp2_3','emp2_4','emp2_5')
df$Empathy <- sjstats::mean_n(df[,Emp_vars], .80)
EMPdf <- df%>%dplyr::select(emp1_1:emp2_5)
psych::alpha(df$EMPdf)
Mgrs_vars<- c('mgrs_1','mgrs_2','mgrs_3','mgrs_5','mgrs_7')
df$MGRS <- sjstats::mean_n(df[,Mgrs_vars], .80)
CONdf <- df%>%dplyr::select(consent_1:consent_6)
psych::alpha(CONdf)
dev.set(dev.next())
EMPdf <- df%>%dplyr::select(emp1_1:emp2_5)
psych::alpha(EMPdf)
MODELdf<- df%>%dplyr::select(Age, Ethnicity, gender, Empathy, Consent, MGRS)
df <-qualtRics::fetch_survey(surveyID = "SV_6zEqY4i6p8rGJz7", time_zone = NULL, verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
df <-qualtRics::fetch_survey(surveyID = "SV_6zEqY4i6p8rGJz7", time_zone = NULL, verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
library(tidyverse)
#the identification key was three parts; the second used letters from their name
#the students were using a mix of upper and lowercase; this makes it all upper case (otherwise R would read them as different people).
#this code makes the second part of the identification key all upper case
df$Key_2 <- toupper(df$Key_2)
#this combines the three parts of the key
df$ID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3)
#this assigns an index number (time1, time2, etc.) by the ID
df <- df%>%
group_by(ID)%>%
mutate(index = order(order(EndDate, decreasing = FALSE)))
#this puts those variables we care about all at the front so we can check our work
#for your project I want to get rid of all those with a number 2,
#unfortunately, the students who took this survey all before we had the key/identification system all have NAs,
#so first I have to recode those kids with NA as NA before I can delete the "2s"
df <-(select (df, ID, index, EndDate, everything()))
#this code recodes all the students with an ID of NA - NA - NA as NA
df$index <- ifelse(df$ID == "NA - NA - NA", NA, df$index)
#this less us properly delete the students who took it a second time (it saved us one student)
df <- df[!(df$index =="2"),]
library(tidyverse)
df %>%
count(Gender)
df$gender <- factor(df$Gender,
levels = c("1","2", "3"),
labels = c("Male", "Female", "Other"))
str(df$gender)
library(sjstats)
Emp_vars <- c('emp1_1','emp1_2','emp1_3','emp1_4','emp2_1','emp2_2','emp2_3','emp2_4','emp2_5')
df$Empathy <- sjstats::mean_n(df[,Emp_vars], .80)
Con_vars <- c('consent_1','consent_2','consent_3','consent_4','consent_5','consent_6')
df$Consent <- sjstats::mean_n(df[,Con_vars], .80)
Mgrs_vars<- c('mgrs_1','mgrs_2','mgrs_3','mgrs_5','mgrs_7')
df$MGRS <- sjstats::mean_n(df[,Mgrs_vars], .80)
EMPdf <- df%>%dplyr::select(emp1_1:emp2_5)
psych::alpha(EMPdf)
str(EMPdf)
View(EMPdf)
View(EMPdf)
#will install the package if not already installed
#if(!require(qualtRics)){install.packages("qualtRics")}
#if(!require(tidyverse)){install.packages("tidyverse")}
#only have to run this ONCE to draw from the same Qualtrics account...but will need to get diff
#library(qualtRics)
#qualtrics_api_credentials(api_key = "Q65NIelIWsnSBw0uUIJtKIm3oYmxBbWxgP6apCT9",
#base_url = "spupsych.az1.qualtrics.com", overwrite = TRUE, install = TRUE)
#readRenviron("~/.Renviron")
#QTRX_csv <- read_survey("KCSARC_VPS220323.csv", strip_html = TRUE, import_id = FALSE, time_zone = FALSE
#surveys <- all_surveys()
#surveys
df <-qualtRics::fetch_survey(surveyID = "SV_6zEqY4i6p8rGJz7", time_zone = NULL, verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
library(tidyverse)
#the identification key was three parts; the second used letters from their name
#the students were using a mix of upper and lowercase; this makes it all upper case (otherwise R would read them as different people).
#this code makes the second part of the identification key all upper case
df$Key_2 <- toupper(df$Key_2)
#this combines the three parts of the key
df$StdID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3)
#this assigns an index number (time1, time2, etc.) by the ID
df <- df%>%
group_by(Std)%>%
mutate(index = order(order(EndDate, decreasing = FALSE)))
library(tidyverse)
#the identification key was three parts; the second used letters from their name
#the students were using a mix of upper and lowercase; this makes it all upper case (otherwise R would read them as different people).
#this code makes the second part of the identification key all upper case
df$Key_2 <- toupper(df$Key_2)
#this combines the three parts of the key
df$StdID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3)
#this assigns an index number (time1, time2, etc.) by the ID
df <- df%>%
group_by(StdID)%>%
mutate(index = order(order(EndDate, decreasing = FALSE)))
#this puts those variables we care about all at the front so we can check our work
#for your project I want to get rid of all those with a number 2,
#unfortunately, the students who took this survey all before we had the key/identification system all have NAs,
#so first I have to recode those kids with NA as NA before I can delete the "2s"
df <-(select (df, StdID, index, EndDate, everything()))
#this code recodes all the students with an ID of NA - NA - NA as NA
df$index <- ifelse(df$StdID == "NA - NA - NA", NA, df$index)
#this less us properly delete the students who took it a second time (it saved us one student)
df <- df[!(df$index =="2"),]
library(tidyverse)
df %>%
count(Gender)
df$gender <- factor(df$Gender,
levels = c("1","2", "3"),
labels = c("Male", "Female", "Other"))
str(df$gender)
library(sjstats)
Emp_vars <- c('emp1_1','emp1_2','emp1_3','emp1_4','emp2_1','emp2_2','emp2_3','emp2_4','emp2_5')
df$Empathy <- sjstats::mean_n(df[,Emp_vars], .80)
Con_vars <- c('consent_1','consent_2','consent_3','consent_4','consent_5','consent_6')
df$Consent <- sjstats::mean_n(df[,Con_vars], .80)
Mgrs_vars<- c('mgrs_1','mgrs_2','mgrs_3','mgrs_5','mgrs_7')
df$MGRS <- sjstats::mean_n(df[,Mgrs_vars], .80)
EMPdf <- df%>%dplyr::select(emp1_1:emp2_5)
psych::alpha(EMPdf)
View(EMPdf)
MODELdf<- df%>%dplyr::select(Age, Ethnicity, gender, Empathy, Consent, MGRS)
MODELdf<- dplyr::filter(MODELdf, rowSums(is.na(MODELdf)) != ncol(MODELdf))
View(MODELdf)
df <- subset(df, select = -(StdID))
library(tidyverse)
df %>%
count(Gender)
df$gender <- factor(df$Gender,
levels = c("1","2", "3"),
labels = c("Male", "Female", "Other"))
str(df$gender)
library(sjstats)
Emp_vars <- c('emp1_1','emp1_2','emp1_3','emp1_4','emp2_1','emp2_2','emp2_3','emp2_4','emp2_5')
df$Empathy <- sjstats::mean_n(df[,Emp_vars], .80)
Con_vars <- c('consent_1','consent_2','consent_3','consent_4','consent_5','consent_6')
df$Consent <- sjstats::mean_n(df[,Con_vars], .80)
Mgrs_vars<- c('mgrs_1','mgrs_2','mgrs_3','mgrs_5','mgrs_7')
df$MGRS <- sjstats::mean_n(df[,Mgrs_vars], .80)
EMPdf <- df%>%dplyr::select(emp1_1:emp2_5)
psych::alpha(EMPdf)
str(EMPdf)
CONdf <- df%>%dplyr::select(consent_1:consent_6)
psych::alpha(CONdf)
MGRSdf<- df%>%dplyr::select(mgrs_1:mgrs_7)
psych::alpha(MGRSdf)
MODELdf<- df%>%dplyr::select(Age, Ethnicity, gender, Empathy, Consent, MGRS)
MODELdf<- dplyr::filter(MODELdf, rowSums(is.na(MODELdf)) != ncol(MODELdf))
install.packages("fvextra")
install.packages("formatR")
