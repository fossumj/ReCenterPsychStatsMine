knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen=999)#eliminates scientific notation
set.seed(220815)
#sample size, M, and SD for Black then White patients
Verbal <- c(rnorm(33, mean=8.37, sd=3.36), rnorm(33, mean = 8.41, sd=3.21))
#set upper bound
Verbal[Verbal>27]<-27
#set lower bound
Verbal[Verbal<0]<-0
#sample size, M, and SD for Black then White patients
Nonverbal <- c(rnorm(33, mean=2.68, sd=.84), rnorm(33, mean = 2.93, sd=.77))
#set upper bound
Nonverbal[Nonverbal>5]<-5
#set lower bound
Nonverbal[Nonverbal<0]<-0
ID<-factor(seq(1,66))
#name factors and identify how many in each group; should be in same order as first row of script
PatientRace<-c(rep("Black", 33), rep("White", 33))
#groups the 3 variables into a single df:  ID#, DV, condition
dfIndSamples <-data.frame(ID, PatientRace, Verbal, Nonverbal)
str(dfIndSamples)
dfIndSamples$PatientRace <- factor(dfIndSamples$PatientRace, levels = c("Black", "White"))
str(dfIndSamples)
#writing the simulated data as a .csv
#write.table(dfIndSamples, file = "dfIndSamples.csv", sep = ',', col.names=TRUE, row.names=FALSE)
#at this point you could clear your environment and then bring the data back in as a .csv
#reading the data back in as a .csv file
#dfIndSamples<- read.csv ('dfIndSamples.csv', header = TRUE)
ggpubr::ggboxplot(dfIndSamples, x = "PatientRace", y = "Verbal", color = "PatientRace", palette =c("#00AFBB", "#FC4E07"), add = "jitter")
sqrt((2.985^2/33) + (3.203^2/33))
(7.615 - 8.891)/0.762
qt(.05/2, 64, lower.tail=TRUE)
qt(.05/2, 64, lower.tail=FALSE)
qt(.05/2, 64, lower.tail=TRUE)
qt(.05/2, 64, lower.tail=FALSE)
(7.614-8.891)- (1.99773*0.762)
(7.614-8.891)+(1.99773*0.762)
-1.675*(sqrt((33+33)/(33*33)))
(-1.6745*-1.6745)/((-1.6745*-1.6745)+(33 + 33 -2))
psych::describe(dfIndSamples$Verbal, type=1) #type=1 produces the type of skew and kurtosis associated with Kline's interpretive guidelines
psych::describeBy(dfIndSamples, group="PatientRace", mat=TRUE, type=1)
View(dfIndSamples)
psych::describeBy(Verbal ~ PatientRace, data = dfIndSamples)
psych::describeBy(dfIndSamples ~ PatientRace, mat=TRUE, type=1)
library(tidyverse)#opening this package so I can use the pipes
shapiro <- dfIndSamples %>%
group_by(PatientRace) %>%
rstatix::shapiro_test(Verbal)
shapiro
library(tidyverse)
set.seed(210731)
#sample size, M and SD for each cell; this will put it in a long file
Negative<-round(c(rnorm(17,mean=1.91,sd=0.73),rnorm(18,mean=3.16,sd=0.19),rnorm(19, mean=3.3, sd=1.05), rnorm(20, mean=3.00, sd=1.07), rnorm(18, mean=2.64, sd=0.95), rnorm(19, mean=2.99, sd=0.80)),3)
#sample size, M and SD for each cell; this will put it in a long file
Positive<-round(c(rnorm(17,mean=4.99,sd=1.38),rnorm(18,mean=3.83,sd=1.13),rnorm(19, mean=4.2, sd=0.82), rnorm(20, mean=4.19, sd=0.91), rnorm(18, mean=4.17, sd=0.60), rnorm(19, mean=3.26, sd=0.94)),3)
ID <- factor(seq(1,111))
Rater <- c(rep("Dayaknese",35), rep("Madurese", 39), rep ("Javanese", 37))
Photo <- c(rep("Dayaknese", 17), rep("Madurese", 18), rep("Dayaknese", 19), rep("Madurese", 20), rep("Dayaknese", 18), rep("Madurese", 19))
#groups the 3 variables into a single df: ID#, DV, condition
Ramdhani_df<- data.frame(ID, Negative, Positive, Rater, Photo)
str(Ramdhani_df)
Ramdhani_df[,'Rater'] <- as.factor(Ramdhani_df[,'Rater'])
Ramdhani_df[,'Photo'] <- as.factor(Ramdhani_df[,'Photo'])
str(Ramdhani_df)
negative.descripts <- psych::describeBy(Negative ~ Rater + Photo, mat = TRUE, data = Ramdhani_df, digits = 3) #digits allows us to round the output
negative.descripts
write.table(negative.descripts, file="NegativeDescripts.csv", sep=",", col.names=TRUE, row.names=FALSE)
ggpubr::ggboxplot(Ramdhani_df, x = "Rater", y = "Negative", color = "Photo",xlab = "Ethnicity of Rater", ylab = "Negative Reaction", add = "jitter", title = "Boxplots Clustered by Rater Ethnicity")
ggpubr::ggboxplot(Ramdhani_df, x = "Photo", y = "Negative", color = "Rater", xlab = "Photo Stimulus",
ylab = "Negative Reaction", add = "jitter", title = "Boxplots Clustered by Ethnicity Represented in Photo Stimulus")
ggpubr::ggline(Ramdhani_df, x = "Rater", y = "Negative", color = "Photo", xlab = "Ethnicity of Rater",
ylab = "Negative Reaction", add = c("mean_se", "dotplot"), title = "Lineplot Clustered by Rater Ethnicity")
#add this for a different color palette:  palette = c("#00AFBB", "#E7B800")
ggpubr::ggline(Ramdhani_df, x = "Photo", y = "Negative", color = "Rater", xlab = "Photo Stimulus",
ylab = "Negative Reaction", add = c("mean_se", "dotplot"), title = "Lineplots Custered by Ethnicity in Photo Stimulus")
mean(Ramdhani_df$Negative)
library(tidyverse)
Ramdhani_df <- Ramdhani_df %>%
mutate(m_dev = Negative-mean(Negative))
head(Ramdhani_df)
sum(Ramdhani_df$m_dev)
Ramdhani_df <- Ramdhani_df %>%
mutate(m_devSQ = m_dev^2)
head(Ramdhani_df)
sum(Ramdhani_df$m_devSQ)
psych::describeBy(Negative ~ Rater + Photo, mat = TRUE, data = Ramdhani_df, digits = 3)
#Note. Recently my students and I have been having intermittent struggles with the describeBy function in the psych package. We have noticed that it is problematic when using .rds files and when using data directly imported from Qualtrics. If you are having similar difficulties, try uploading the .csv file and making the appropriate formatting changes.
mean(Ramdhani_df$Negative)
17*(1.818 - 2.947)^2 + 18*(2.524 - 2.947)^2 + 19*(3.301 - 2.947)^2 + 18*(3.129 - 2.947)^2 + 19*(3.465 - 2.947)^2 + 20*(3.297 - 2.947)^2
psych::describeBy(Negative ~ Rater + Photo, mat = TRUE, data = Ramdhani_df, digits = 3)
((.768^2)*(17-1))+ ((.742^2)*(18-1)) + ((1.030^2)*(19-1)) + ((.156^2)*(18-1)) + ((.637^2)*(19-1)) + ((1.332^2)*(20-1))
111 - 6
35.415 + 79.321
psych::describeBy(Negative ~ Rater, mat = TRUE, data = Ramdhani_df, digits = 3)
mean(Ramdhani_df$Negative)
35*(2.491 - 2.947)^2 + 37*(3.007 - 2.947)^2 +39*(3.299 - 2.947)^2
psych::describeBy(Negative ~ Photo, mat = TRUE, data = Ramdhani_df, digits = 3)
mean(Ramdhani_df$Negative)
54*(2.575 - 2.947)^2 + 57*(3.300 - 2.947)^2
35.415 - (12.243 + 14.575)
#hand-calculating the MS values
35.415/5   #Model
12.243/2   #a: Rater
14.575/1   #b:  Photo
8.597/2    #axb interaction term
79.321/105 #residual
#hand-calculating the F values
7.083/.755  #Model
6.122/.755  #a: Rater
14.575/.755 #b:  Photo
4.299/.755  #axb interaction term
#looking up the F critical values
qf(.05, 5, 105, lower.tail=FALSE)#Model F critical value
qf(.05, 2, 105, lower.tail=FALSE)#a and axb F critical value
qf(.05, 1, 105, lower.tail=FALSE)#b F critical value
TwoWay_neg<-aov(Negative~Rater*Photo, Ramdhani_df)
summary(TwoWay_neg)
model.tables(TwoWay_neg,"means")
psych::describeBy(Negative ~ Rater + Photo, mat = TRUE, data = Ramdhani_df, digits = 3, type = 1)
#creates object of residuals
resid_neg<- residuals(TwoWay_neg)
hist(resid_neg)
qqnorm(resid_neg)
shapiro.test(resid_neg)
Ramdhani_df%>%
rstatix::identify_outliers(Negative)
Ramdhani_df%>%
group_by(Rater, Photo)%>%
rstatix::identify_outliers(Negative)
#Ramdhani_df <- dplyr::filter(Ramdhani_df, ID != "18")
rstatix::levene_test(Ramdhani_df, Negative ~ Rater*Photo)
omnibus2w <- rstatix::anova_test(Ramdhani_df, Negative ~ Rater*Photo, type="2", detailed=TRUE)
omnibus2w
.05/6
Ramdhani_df%>%
dplyr::group_by(Rater)%>%
rstatix::anova_test(Negative ~ Photo)
library(tidyverse)
pwPHwiETH <- Ramdhani_df%>%
group_by(Rater)%>%
rstatix::emmeans_test(Negative ~ Photo, detailed = TRUE, p.adjust.method = "bonferroni")
install.packages("emmeans")
warnings()
warnings()
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
install.packages("tlmgr")
update.packages(ask = FALSE, checkBuilt = TRUE)
library(digest)
remove.packages("digest")
install.packages("digest")
tinytex::tlmgr_update()
tinytex::reinstall_tinytex()
remove.packages("tinytex")
options(tinytex.verbose = TRUE)
tinytex::install_tinytex()
install.packages('tinytex')
install.packages("tinytex")
warnings()
warnings()
tinytex::install_tinytex()
install.packages("formatR")
tinytex::pdflatex('test.tex')
knitr::opts_chunk$set(echo = TRUE)
writeLines(c(
'\\documentclass{article}',
'\\begin{document}', 'Hello world!', '\\end{document}'
), 'test.tex')
tinytex::pdflatex('test.tex')
citr:::insert_citation()
install.packages("ghostscript")
psych::describeBy(IndT_df ~ Dept, data = IndT_df, type =1, mat=TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen = 999)
big <- readRDS("ReC.rds")
JustANOVA <- subset(big, Course == "ANOVA")
#Creates a list of the variables that belong to that scale
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
#Calculates a mean if at least 75% of the items are non-missing; adjusts the calculating when there is missingness
JustANOVA$TradPed <- sjstats::mean_n(JustANOVA[, TradPed_vars], .75)
IndT_df <-(dplyr::select (JustANOVA, Dept, TradPed))
IndT_df <- na.omit(IndT_df)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen = 999)
big <- readRDS("ReC.rds")
JustANOVA <- subset(big, Course == "ANOVA")
#Creates a list of the variables that belong to that scale
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
#Calculates a mean if at least 75% of the items are non-missing; adjusts the calculating when there is missingness
JustANOVA$TradPed <- sjstats::mean_n(JustANOVA[, TradPed_vars], .75)
IndT_df <-(dplyr::select (JustANOVA, Dept, TradPed))
IndT_df <- na.omit(IndT_df)
str(IndT_df)
IndT_df$Dept <- factor(IndT_df$Dept)
str(IndT_df$Dept)
psych::describeBy(IndT_df ~ Dept, data = IndT_df, type =1, mat=TRUE)
IndT_df$Dept <- factor(IndT_df$Dept)
str(IndT_df$Dept)
psych::describeBy(IndT_df ~ Dept, data = IndT_df, type =1, mat=TRUE)
View(IndT_df)
View(IndT_df)
psych::describeBy(TradPed ~ Dept, data = IndT_df, type =1, mat=TRUE)
psych::describeBy(IndT_df ~ Dept, type =1, mat=TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen = 999)
big <- readRDS("ReC.rds")
JustANOVA <- subset(big, Course == "ANOVA")
#Creates a list of the variables that belong to that scale
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
#Calculates a mean if at least 75% of the items are non-missing; adjusts the calculating when there is missingness
JustANOVA$TradPed <- sjstats::mean_n(JustANOVA[, TradPed_vars], .75)
IndT_df <-(dplyr::select (JustANOVA, Dept, TradPed))
IndT_df <- na.omit(IndT_df)
str(IndT_df)
IndT_df$Dept <- factor(IndT_df$Dept)
str(IndT_df$Dept)
psych::describeBy(IndT_df ~ Dept, type =1, mat=TRUE)
library(tidyverse)#opening this package so I can use the pipes
shapiro <- IndT_df%>%
group_by(Dept) %>%
rstatix::shapiro_test(TradPed)
shapiro
psych::pairs.panels(IndT_df)
rstatix::levene_test(IndT_df, TradPed ~ Dept, center=median)
indT.test <- rstatix::t_test(IndT_df, TradPed~Dept, var.equal=TRUE, detailed=TRUE) %>%
rstatix::add_significance()
indT.test
rstatix::cohens_d(IndT_df, TradPed ~ Dept, var.equal = TRUE)
apaTables::apa.1way.table(Dept, TradPed, IndT_df)
indT.box <- ggpubr::ggboxplot(IndT_df, x = "Dept", y = "TradPed", color = "Dept", palette=c("#00AFBB", "#FC4E07"), add = "jitter",  title = "Figure 1. Traditional Pedagogy as a Function of Academic Department")
ind.testT <- indT.test %>% rstatix::add_xy_position(x = "Dept") #autocomputes p-value labels positions
indT.box <- indT.box +
ggpubr::stat_pvalue_manual(ind.testT, label = "p.signif", tip.length=.02, hide.ns = FALSE, y.position = c(6)) +
labs(subtitle = rstatix::get_test_label(indT.test, detailed=TRUE)) #adds t-test results
indT.box
pwr::pwr.t.test(d = 0.30, n = 112, power = NULL, sig.level = 0.05,
type = "two.sample", alternative = "two.sided")
pwr::pwr.t.test(d = 0.3, n = NULL, power = 0.8, sig.level = 0.05,
type = "two.sample", alternative = "two.sided")
psych::describeBy(IndT_df, group = "Dept", type =1, mat=TRUE)
psych::describeBy(IndT_df ~group = "Dept", type =1, mat=TRUE)
psych::describeBy(IndT_df ~ "Dept", type =1, mat=TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen = 999)
big <- readRDS("ReC.rds")
JustANOVA <- subset(big, Course == "ANOVA")
#Creates a list of the variables that belong to that scale
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
#Calculates a mean if at least 75% of the items are non-missing; adjusts the calculating when there is missingness
JustANOVA$TradPed <- sjstats::mean_n(JustANOVA[, TradPed_vars], .75)
IndT_df <-(dplyr::select (JustANOVA, Dept, TradPed))
IndT_df <- na.omit(IndT_df)
str(IndT_df)
IndT_df$Dept <- factor(IndT_df$Dept)
str(IndT_df$Dept)
psych::describeBy(IndT_df ~ Dept, type =1, mat=TRUE)
library(tidyverse)#opening this package so I can use the pipes
shapiro <- IndT_df%>%
group_by(Dept) %>%
rstatix::shapiro_test(TradPed)
shapiro
psych::pairs.panels(IndT_df)
rstatix::levene_test(IndT_df, TradPed ~ Dept, center=median)
indT.test <- rstatix::t_test(IndT_df, TradPed~Dept, var.equal=TRUE, detailed=TRUE) %>%
rstatix::add_significance()
indT.test
rstatix::cohens_d(IndT_df, TradPed ~ Dept, var.equal = TRUE)
apaTables::apa.1way.table(Dept, TradPed, IndT_df)
indT.box <- ggpubr::ggboxplot(IndT_df, x = "Dept", y = "TradPed", color = "Dept", palette=c("#00AFBB", "#FC4E07"), add = "jitter",  title = "Figure 1. Traditional Pedagogy as a Function of Academic Department")
ind.testT <- indT.test %>% rstatix::add_xy_position(x = "Dept") #autocomputes p-value labels positions
indT.box <- indT.box +
ggpubr::stat_pvalue_manual(ind.testT, label = "p.signif", tip.length=.02, hide.ns = FALSE, y.position = c(6)) +
labs(subtitle = rstatix::get_test_label(indT.test, detailed=TRUE)) #adds t-test results
indT.box
pwr::pwr.t.test(d = 0.30, n = 112, power = NULL, sig.level = 0.05,
type = "two.sample", alternative = "two.sided")
pwr::pwr.t.test(d = 0.3, n = NULL, power = 0.8, sig.level = 0.05,
type = "two.sample", alternative = "two.sided")
psych::describeBy(IndT_df ~ Dept, type =1, mat=TRUE)
sqrt((0.7547259^2/81) + (1.0948953^2/31))
(4.129630 - 3.870968)/0.2137828
qt(0.05/2, 112, lower.tail = TRUE)
qt(0.05/2, 112, lower.tail = FALSE)
(4.129630 - 3.870968) - (1.981372 * 0.2137828)
(4.129630 - 3.870968) + (1.981372 * 0.2137828)
1.209929 * (sqrt((81 + 31)/(81 * 31)))
file.create('.nojekyll')
ReCdf <- readRDS("ReC.rds")
JustANOVA <- subset(ReCdf, Course == "ANOVA")
library(tidyverse)
tiny1 <- JustANOVA %>%
dplyr::select (OvInstructor)
tiny1 <- na.omit(tiny1)
str(tiny1$OvInstructor)
pastecs::stat.desc(tiny1$OvInstructor, norm=TRUE)
rstatix::t_test(tiny1, OvInstructor ~ 1, mu = 4.4, detailed = TRUE)
rstatix::cohens_d(tiny1, OvInstructor ~ 1, ref.group = NULL, mu = 4.4)
ggpubr::ggboxplot(tiny1$OvInstructor, ylab = "Course Evaluation Ratings", xlab = FALSE,
add = "jitter", title = "Figure 1. Overall Instructor Ratings for ANOVA")
pwr::pwr.t.test(d = -0.1416285	, n = 82, power = NULL, sig.level = 0.05,
type = "one.sample", alternative = "two.sided")
dfReC <- readRDS("ReC.rds")
ReCdf <- readRDS("ReC.rds")
JustANOVA <- subset(ReCdf, Course == "ANOVA")
library(tidyverse)
tiny3 <- JustANOVA %>%
dplyr::select (OvInstructor, OvCourse, MyContribution)
psych::describe(tiny3)
psych::pairs.panels(tiny3)
apaTables::apa.cor.table(tiny3)
ReCdf <- readRDS("ReC.rds")
JustANOVA <- subset(ReCdf, Course == "ANOVA")
library(tidyverse)
tiny3 <- JustANOVA %>%
dplyr::select (OvInstructor, OvCourse, MyContribution)
tiny3 <- na.omit(tiny3)
tiny3$M_OvI <- mean(tiny3$OvInstructor, na.rm=TRUE)
tiny3$Mdev_OvI <- (tiny3$OvInstructor-tiny3$M_OvI)
View(tiny3)
round(sum(tiny3$Mdev_OvI, na.rm = TRUE), 3)
tiny3$abslt_mOvI <- abs(tiny3$Mdev_OvI)
round(sum(tiny3$abslt_mOvI, na.rm = TRUE), 3)
round(mean(tiny3$abslt_mOvI, na.rm = TRUE), 3)
tiny3$mdev2_OvI <- (tiny3$Mdev_OvI * tiny3$Mdev_OvI)
tiny3$mdev2_OvI <- (tiny3$Mdev_OvI * tiny3$Mdev_OvI)
sum(tiny3$mdev2_OvI, na.rm = TRUE)
var_OvI <- sum(tiny3$mdev2_OvI/((nrow(tiny3) - 1)))
var_OvI
115.0973/(113-1)
var(tiny3$OvInstructor, na.rm = TRUE) #checking my work
sd_OvI <- sqrt(var_OvI)#calculating with the object I created
sd_OvI
sqrt (1.027655)#calculated with the actual numbers
sd(tiny3$OvInstructor)#checking my work with the code from baseR
#first the mean
tiny3$M_MyC <- mean(tiny3$MyContribution, na.rm=TRUE)
#second the mean deviation
tiny3$Mdev_MyC <- (tiny3$MyContribution-tiny3$M_MyC)
#fourth the variance
var_MyC <- sum(tiny3$mdev2_MyC/((nrow(tiny3) - 1)))
var_MyC
#finally the standard deviation
sd_MyC <- sqrt(var_MyC)
sd_MyC#checking my work
sd(tiny3$MyContribution)#checking my work
tiny3$crossproduct <- (tiny3$Mdev_OvI * tiny3$Mdev_MyC)
xp_sum <- sum(tiny3$crossproduct)
xp_sum
cov <- (1/(113-1)) * 46.74336
cov
0.4173514/(1.013733*0.8338)
cor.test(tiny3$OvInstructor, tiny3$MyContribution)
ReCdf <- readRDS("ReC.rds")
JustANOVA <- subset(ReCdf, Course == "ANOVA")
library(tidyverse)
tiny1 <- JustANOVA %>%
dplyr::select (OvInstructor)
tiny1 <- na.omit(tiny1)
str(tiny1$OvInstructor)
pastecs::stat.desc(tiny1$OvInstructor, norm=TRUE)
rstatix::t_test(tiny1, OvInstructor ~ 1, mu = 4.4, detailed = TRUE)
rstatix::cohens_d(tiny1, OvInstructor ~ 1, ref.group = NULL, mu = 4.4)
ggpubr::ggboxplot(tiny1$OvInstructor, ylab = "Course Evaluation Ratings", xlab = FALSE,
add = "jitter", title = "Figure 1. Overall Instructor Ratings for ANOVA")
pwr::pwr.t.test(d = -0.211	, n = 113, power = NULL, sig.level = 0.05,
type = "one.sample", alternative = "two.sided")
pwr::pwr.t.test(d = -0.211	, n = 113, power = NULL, sig.level = 0.05,
type = "one.sample", alternative = "two.sided")
pwr::pwr.t.test(d = -0.211, n = NULL, power = 0.8, sig.level = 0.05,
type = "one.sample", alternative = "two.sided")
mean(tiny1$OvInstructor, na.rm=TRUE)
#first the mean
tiny1$M_OvInst <- mean(tiny1$OvInstructor, na.rm=TRUE)
#second the mean deviation
tiny1$Mdev_OvInst <- (tiny1$OvInstructor-tiny1$M_OvInst)
#third the mean deviation squared
tiny1$mdev2_OvInst <- (tiny1$Mdev_OvInst  * tiny1$Mdev_OvInst)
#fourth the variance
var_OvInst <- sum(tiny1$mdev2_OvInst /((nrow(tiny1) - 1)))
var_OvInst
#finally the standard deviation
sd_OvInst <- sqrt(var_OvInst)
sd_OvInst
(4.185 - 4.4)/(1.027655/sqrt(113))
(4.185841 - 4.4)/(1.027655/sqrt(114))
(4.185841 - 4.4)/(1.013733/sqrt(114))
(4.185841 - 4.4)/(1.013733/sqrt(113))
(4.185841 - 4.4)/(1.013733/sqrt(113))
113 - 1
qt(p = 0.05/2, df = 113, lower.tail = FALSE)
(4.185841) - ((1.989686)*(1.98118/sqrt(113)))
(4.185841) + ((1.989686)*(1.98118/sqrt(113)))
(4.185841) - ((1.98118)*(1.013733/sqrt(113)))
(4.185841) + ((1.98118)*(1.013733/sqrt(113)))
#First formula
(4.185841 - 4.4)/1.013733
#Second formula
-2.245701/sqrt(113)
big <- readRDS("ReC.rds")
JustANOVA <- subset(big, Course == "ANOVA")
#Creates a list of the variables that belong to that scale
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
#Calculates a mean if at least 75% of the items are non-missing; adjusts the calculating when there is missingness
JustANOVA$TradPed <- sjstats::mean_n(JustANOVA[, TradPed_vars], .75)
IndT_df <-(dplyr::select (JustANOVA, Dept, TradPed))
IndT_df <- na.omit(IndT_df)
str(IndT_df)
IndT_df$Dept <- factor(IndT_df$Dept)
str(IndT_df$Dept)
psych::describeBy(IndT_df ~ Dept,  type =1, mat=TRUE)
library(tidyverse)#opening this package so I can use the pipes
shapiro <- IndT_df%>%
group_by(Dept) %>%
rstatix::shapiro_test(TradPed)
shapiro
psych::pairs.panels(IndT_df)
rstatix::levene_test(IndT_df, TradPed ~ Dept, center=median)
indT.test <- rstatix::t_test(IndT_df, TradPed~Dept, var.equal=TRUE, detailed=TRUE) %>%
rstatix::add_significance()
indT.test
rstatix::cohens_d(IndT_df, TradPed ~ Dept, var.equal = TRUE)
apaTables::apa.1way.table(Dept, TradPed, IndT_df)
indT.box <- ggpubr::ggboxplot(IndT_df, x = "Dept", y = "TradPed", color = "Dept", palette=c("#00AFBB", "#FC4E07"), add = "jitter",  title = "Figure 1. Traditional Pedagogy as a Function of Academic Department")
ind.testT <- indT.test %>% rstatix::add_xy_position(x = "Dept") #autocomputes p-value labels positions
indT.box <- indT.box +
ggpubr::stat_pvalue_manual(ind.testT, label = "p.signif", tip.length=.02, hide.ns = FALSE, y.position = c(6)) +
labs(subtitle = rstatix::get_test_label(indT.test, detailed=TRUE)) #adds t-test results
indT.box
pwr::pwr.t.test(d = 0.30, n = 112, power = NULL, sig.level = 0.05,
type = "two.sample", alternative = "two.sided")
pwr::pwr.t.test(d = 0.3, n = NULL, power = 0.8, sig.level = 0.05,
type = "two.sample", alternative = "two.sided")
psych::describeBy(IndT_df ~ Dept, type =1, mat=TRUE)
sqrt((0.7547259^2/81) + (1.0948953^2/31))
(4.129630 - 3.870968)/0.2137828
sqrt((0.7547259^2/81) + (1.0948953^2/31))
(4.129630 - 3.870968)/0.2137828
qt(0.05/2, 112, lower.tail = TRUE)
qt(0.05/2, 112, lower.tail = FALSE)
(4.129630 - 3.870968) - (1.209929 * 0.2137828)
(4.129630 - 3.870968) + (1.209929 * 0.2137828)
1.209929 * (sqrt((81 + 31)/(81 * 31)))
Paired_df <-(dplyr::select (ReC.rds, StndtID, Course, SCRPed))
big <- readRDS("ReC.rds")
Paired_df <-(dplyr::select (ReC.rds, StndtID, Course, SCRPed))
Paired_df <-(dplyr::select (ReC, StndtID, Course, SCRPed))
Paired_df <-(dplyr::select (big, StndtID, Course, SCRPed))
View(big)
Paired_df <-(dplyr::select (big, deID, Course, SCRPed))
#Creates a list of the variables that belong to that scale
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
#Calculates a mean if at least 75% of the items are non-missing; adjusts the calculating when there is missingness
larger$TradPed <- sjstats::mean_n(JustANOVA[, TradPed_vars], .75)
#Creates a list of the variables that belong to that scale
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
#Calculates a mean if at least 75% of the items are non-missing; adjusts the calculating when there is missingness
larger$TradPed <- sjstats::mean_n(larger[, TradPed_vars], .75)
#Creates a list of the variables that belong to that scale
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
#Calculates a mean if at least 75% of the items are non-missing; adjusts the calculating when there is missingness
larger$TradPed <- sjstats::mean_n(larger[, TradPed_vars], .75)
larger <- readRDS("ReC.rds")
#Creates a list of the variables that belong to that scale
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
#Calculates a mean if at least 75% of the items are non-missing; adjusts the calculating when there is missingness
larger$TradPed <- sjstats::mean_n(larger[, TradPed_vars], .75)
larger <- readRDS("ReC.rds")
#Creates a list of the variables that belong to that scale
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
#Calculates a mean if at least 75% of the items are non-missing; adjusts the calculating when there is missingness
larger$TradPed <- sjstats::mean_n(larger[, TradPed_vars], .75)
#Creates a list of the variables that belong to that scale
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
#Calculates a mean if at least 75% of the items are non-missing; adjusts the calculating when there is missingness
larger$TradPed <- sjstats::mean_n(larger[, ..TradPed_vars], .75)
Paired_df <-(dplyr::select (larger, deID, Course, TradPed))
Paired_df <- subset(Paired_df, Course == "ANOVA" | Course == "Multivariate")
View(Paired_df)
str(Paired_df)
paired_wide <- reshape2::dcast(data = Paired_df, formula =deID ~ Course, value.var = "TradPed")
View(paired_wide)
str(paired_wide)
paired_wide <- na.omit(paired_wide)
View(paired_wide)
paired_wide$DIFF <- paired_wide$ANOVA - paired_wide$Multivariate
psych::describe(paired_wide)
psych::pairs.panels(paired_wide)
rstatix::shapiro_test(paired_wide, Diff)
rstatix::shapiro_test(paired_wide, DIFF)
