B_sd <- 3.21
AB_r <- 0.3
#the faux package can simulate a variety of data. This function within the faux package will use the objects above to simulate paired samples data
paired_V <- faux::rnorm_multi(
n = sub_n,
vars = 2,
r = AB_r,
mu = c(A_mean, B_mean),
sd = c(A_sd, B_sd),
varnames = c("Verbal_BL", "Verbal_WH")
)
paired_V <- paired_V %>% dplyr::mutate(PhysID = row_number())
#Here, I repeated the process for the nonverbal variable.
sub_n <- 33
A_mean <- 2.68
B_mean <- 2.93
A_sd <- .84
B_sd <- .77
AB_r <- 0.9
paired_NV <- faux::rnorm_multi(
n = sub_n,
vars = 2,
r = AB_r,
mu = c(A_mean, B_mean),
sd = c(A_sd, B_sd),
varnames = c("NVerb_BL", "NVerb_WH")
)
#This code produced an ID number for each physician
paired_NV <- paired_NV %>% dplyr::mutate(PhysID = row_number())
#This data joined the two sets of data.
#Note, I did not write any code that assumed tha the verbal and nonverbal data came from the same physician.  Full confession:  I'm not quite sure how to do that just yet.
dfPairedSamples <- dplyr::full_join(paired_V, paired_NV, by = c("PhysID"))
dfPairedSamples <- dfPairedSamples%>%dplyr::select(PhysID, everything())
View(dfPairedSamples)
str(dfPairedSamples)
#writing the simulated data as a .csv
write.table(dfPairedSamples, file = "dfPairedSamples.csv", sep = ',', col.names=TRUE, row.names=FALSE)
#at this point you could clear your environment and then bring the data back in as a .csv
#reading the data back in as a .csv file
#dfPairedSamples<- read.csv ('dfPairedSamples.csv', header = TRUE)
saveRDS(dfPairedSamples, 'dfPairedSamples.rds')
#saveRDS(dfPairedSamples, 'dfPairedSamples.rds')
dfPairedSamples <- readRDS('dfPairedSamples.rds')
View(dfPairedSamples)
#saveRDS(dfPairedSamples, 'dfPairedSamples.rds')
#dfPairedSamples <- readRDS('dfPairedSamples.rds')
str(dfPairedSamples)
#Creating the Verbal_D variable within the dfPairedSamples df
#Doing the "math" that informs that variable
dfPairedSamples$Verbal_D <- (dfPairedSamples$Verbal_BL - dfPairedSamples$Verbal_WH)
#Displaying the first six rows of the df to show that the difference score now exists
head(dfPairedSamples)
ggpubr::ggpaired(dfPairedSamples, cond1 = "Verbal_BL", cond2 ="Verbal_WH", color = "condition",  line.color = "gray", palette =c("npg"), xlab = "Patient Race", ylab = "Verbal Communication Rating")
ggpubr::ggpaired(dfPairedSamples, cond1 = "Verbal_BL", cond2 ="Verbal_WH", color = "condition",  line.color = "gray", palette =c("npg"), xlab = "Patient Race", ylab = "Verbal Communication Rating", add = "jitter")
ggpubr::ggpaired(dfPairedSamples, cond1 = "Verbal_BL", cond2 ="Verbal_WH", color = "condition",  line.color = "gray", palette =c("npg"), xlab = "Patient Race", ylab = "Verbal Communication Rating")
psych::describe(dfPairedSamples)
.08/(4.14/sqrt(33))
qt(.05/2, 32, lower.tail=TRUE)
qt(.05/2, 32, lower.tail=FALSE)
qt(.05/2, 32, lower.tail=TRUE)
qt(.05/2, 32, lower.tail=FALSE)
qt(.05/2, 32, lower.tail=TRUE)
qt(.05/2, 32, lower.tail=FALSE)
qt(.05/2, 32, lower.tail=TRUE)
qt(.05/2, 32, lower.tail=FALSE)
.08-(2.037*((4.14/(sqrt(33)))))
.08+(2.037*((4.14/sqrt(33))))
.08/4.14
0.111/(sqrt(33))
(33*(.08^2))/((33*(.08^2)) + ((33-1)*(4.14^2)))
(0.111^2)/((0.111^2)+(33-1))
lsr::pairedSamplesTTest(
formula = ~Verbal_BL + Verbal_WH,
data = dfPairedSamples
)
library(tidyverse)#needed to use the pipe
#Creating a smaller df to include only the variables I want in the table
PairedDescripts <- dfPairedSamples%>%
select(Verbal_BL, Verbal_WH, Verbal_D)
#using the apa.cor.table function for means, standard deviations, and correlations
#the filename command will write the table as a word document to your file
apaTables::apa.cor.table(PairedDescripts, table.number=1, filename="Tab1_PairedV.doc")
ggpubr::ggpaired(dfPairedSamples, cond1 = "Verbal_BL", cond2 ="Verbal_WH", color = "condition",  line.color = "gray", palette =c("npg"), xlab = "Patient Race", ylab = "Verbal Communication Rating", title = "Figure 1. Physician Verbal Engagement as a Function of Patient Race")
pwr::pwr.t.test(d=(0-.08)/4.14,n = 33, power=NULL,sig.level=0.05,type="paired",alternative="two.sided")
pwr::pwr.t.test(d=(.08)/4.14,n = NULL, power=0.8,sig.level=0.05,type="paired",alternative="two.sided")
pwr::pwr.t.test(d=(.08)/4.14,n = 33, power=NULL,sig.level=0.05,type="paired",alternative="two.sided")
pwr::pwr.t.test(d=(.08)/4.14,n = NULL, power=0.8,sig.level=0.05,type="paired",alternative="two.sided")
pwr::pwr.t.test(d=(.08)/4.14,n = NULL, power=0.8,sig.level=0.05,type="paired",alternative="two.sided")
set.seed(220820)
#These define the characteristics of the verbal variable. It is essential that the object names (e.g., A_mean) are not changed because they will be fed to the function in the faux package.
sub_n <- 21022
A_mean <- 8.37
B_mean <- 8.41
A_sd <- 3.36
B_sd <- 3.21
AB_r <- 0.3
#the faux package can simulate a variety of data. This function within the faux package will use the objects above to simulate paired samples data
paired_V2 <- faux::rnorm_multi(
n = sub_n,
vars = 2,
r = AB_r,
mu = c(A_mean, B_mean),
sd = c(A_sd, B_sd),
varnames = c("Verbal_BL", "Verbal_WH")
)
lsr::pairedSamplesTTest(
formula = ~Verbal_BL + Verbal_WH,
data = paired_V2
)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
15+7+11
knitr::opts_chunk$set(echo = TRUE)
df <- readRDS('TEPPout.rds')
View(df)
---
title: "demo_ReadySetR"
author: "lhbikos"
date: '2022-09-12'
output: html_document
---
2022-1966
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
2022-1966
install.packages("psych")
install.packages("psych")
knitr::opts_chunk$set(echo = TRUE)
set.seed(220911)
# sample size, M and SD for each group
Accurate <- c(rnorm(30, mean = 1.18, sd = 0.8), rnorm(30, mean = 1.83,
sd = 0.58), rnorm(30, mean = 1.76, sd = 0.56))
# set upper bound for DV
Accurate[Accurate > 3] <- 3
# set lower bound for DV
Accurate[Accurate < 0] <- 0
# IDs for participants
ID <- factor(seq(1, 90))
# name factors and identify how many in each group; should be in same
# order as first row of script
COND <- c(rep("High", 30), rep("Low", 30), rep("Control", 30))
# groups the 3 variables into a single df: ID, DV, condition
Acc_sim30 <- data.frame(ID, COND, Accurate)
#write.table(Acc_sim30, file = "Acc_sim30.csv", sep = ',', col.names=TRUE, row.names=FALSE)
#at this point you could clear your environment and then bring the data back in as a .csv
#reading the data back in as a .csv file
#dfIndSamples<- read.csv ('dfIndSamples.csv', header = TRUE)
set.seed(220911)
# sample size, M and SD for each group
Accurate <- c(rnorm(30, mean = 1.18, sd = 0.8), rnorm(30, mean = 1.83,
sd = 0.58), rnorm(30, mean = 1.76, sd = 0.56))
# set upper bound for DV
Accurate[Accurate > 3] <- 3
# set lower bound for DV
Accurate[Accurate < 0] <- 0
# IDs for participants
ID <- factor(seq(1, 90))
# name factors and identify how many in each group; should be in same
# order as first row of script
COND <- c(rep("High", 30), rep("Low", 30), rep("Control", 30))
# groups the 3 variables into a single df: ID, DV, condition
Acc_sim30 <- data.frame(ID, COND, Accurate)
write.table(Acc_sim30, file = "Acc_sim30.csv", sep = ',', col.names=TRUE, row.names=FALSE)
#at this point you could clear your environment and then bring the data back in as a .csv
#reading the data back in as a .csv file
df_csv<- read.csv ('Acc_sim30.csv', header = TRUE)
View(df_csv)
View(df_csv)
set.seed(220911)
# sample size, M and SD for each group
Accurate <- c(rnorm(30, mean = 1.18, sd = 0.8), rnorm(30, mean = 1.83,
sd = 0.58), rnorm(30, mean = 1.76, sd = 0.56))
# set upper bound for DV
Accurate[Accurate > 3] <- 3
# set lower bound for DV
Accurate[Accurate < 0] <- 0
# IDs for participants
ID <- factor(seq(1, 90))
# name factors and identify how many in each group; should be in same
# order as first row of script
COND <- c(rep("High", 30), rep("Low", 30), rep("Control", 30))
# groups the 3 variables into a single df: ID, DV, condition
Acc_sim30 <- data.frame(ID, COND, Accurate)
saveRDS(Acc_sim30, 'Acc_sim30.rds')
df_rds <- readRDS('Acc_sim30.rds')
psych::describe(df_rds)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
#obtained with the survey ID
#"surveyID" should be the ID from above
#"verbose" prints messages to the R console
#"label", when TRUE, imports data as text responses; if FALSE prints the data as numerical responses
#"convert", when TRUE, attempts to convert certain question types to the "proper" data type in R; because I don't like guessing, I want to set up my own factors.
#"force_request", when TRUE, always downloads the survey from the API instead of from a temporary directory (i.e., it always goes to the primary source)
# "import_id", when TRUE includes the unique Qualtrics-assigned ID; since I have provided labels, I want false
#Out of the blue, I started getting an error, that R couldn't find function "fetch_survey."  After trying a million things, adding qualtRics:: to the front of it solved the problem
QTRX_df <-qualtRics::fetch_survey(surveyID = "SV_b2cClqAlLGQ6nLU", time_zone = NULL, verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
surveys <- all_surveys()
qualtRics::surveys <- all_surveys()
surveys <- qualtRics::all_surveys()
#View this as an object (found in the right: Environment).
#Get survey id # for the next command
#If this is showing you the WRONG list of surveys, you are pulling from the wrong Qualtrics account (i.e., maybe this one instead of your own). Go back and change your API token (it saves your old one). Changing the API likely requires a restart of R.
surveys
View(QTRX_df)
#Note, this script results in a different simulation than is in the ReadySetR lesson
#sets a random seed so that we get the same results each time
set.seed(210820)
#sample size, M and SD for each group
Accurate <- c(rnorm(30, mean=1.18, sd=0.80), rnorm(30, mean=1.83, sd = 0.58), rnorm(30, mean = 1.76, sd = 0.56))
#set upper bound for DV
Accurate[Accurate>3]<-3
#set lower bound for DV
Accurate[Accurate<0]<-0
#sample size, M and SD for each group
moreTalk <- c(rnorm(30, mean=-.82, sd=0.91), rnorm(30, mean=-0.39, sd = 0.66), rnorm(30, mean = -0.04, sd = 0.71))
#set upper bound for DV
moreTalk[moreTalk>2]<- 2
#set lower bound for DV
moreTalk[moreTalk<-2]<- -2
#IDs for participants
ID<-factor(seq(1,90))
#name factors and identify how many in each group; should be in same order as first row of script
COND<-c(rep("High", 30), rep("Low", 30), rep("Control", 30))
#groups the 3 variables into a single df:  ID#, DV, condition
accSIM30 <-data.frame(ID, COND, Accurate, moreTalk)
str(accSIM30)
#convert variable to factor
accSIM30$COND <- factor(accSIM30$COND)
str(accSIM30)
#ordering the factor
accSIM30$COND <- factor(accSIM30$COND, levels = c("Control", "Low", "High"))
#another structure check
str(accSIM30)
aggregate(Accurate ~ COND, accSIM30, mean)
aggregate(Accurate ~ COND, accSIM30, sd)
#plots DV by IV
gplots::plotmeans (formula = Accurate ~ COND,
data = accSIM30,
xlab = "Racial Loading Condition",
ylab = "Accuracy of Confederate's Impression",
n.label = TRUE
)
#this code could be more elegantly written in one row
#plotmeans (formula = Accurate ~ COND, data = accSIM30, xlab = "Racial Loading Condition", ylab = "Accuracy of Confederate's Impression", n.label = TRUE)
gplots::boxplot2 (Accurate ~ COND, data = accSIM30, xlab = "Racial Loading Condition", ylab = "Accuracy of Confederate's Impression", n.label = TRUE)
width <- 7
height <- 4
# params
mu <- c(-4, -.25, 3.5)
sig <- 2
# data
x <- seq(-3,3,.1)
x1 <- x*sig + mu[1]
x2 <- x*sig + mu[2]
x3 <- x*sig + mu[3]
y1 <- dnorm( x1, mu[1], sig )
y2 <- dnorm( x2, mu[2], sig )
y3 <- dnorm( x3, mu[3], sig )
# set up window
plot.new() # create graphics device
plot.window(xlim = c(-10,10), ylim = c(0,.25)) # define plot area
axis(side = 1, # axis located below
col = "gray20",  # coloured gray
at = c(-10,mu,10), # tick marks located at
labels = c("","group 1","group 2","group 3","")
)
# plot densities
lines(x1,y1, type = "l", col = "gray20")
lines(x2,y2, type = "l", col = "gray20")
lines(x3,y3, type = "l", col = "gray20")
# arrows
arrows(
mu[1],.15, # from
mu[2],.15, # to
code = 3,  # arrows on both ends
lwd = 2,   # thick line
)
arrows(
mu[2],.125, # from
mu[3],.125, # to
code = 3,  # arrows on both ends
lwd = 2,   # thick line
)
arrows(
mu[1],.1, # from
mu[3],.1, # to
code = 3,  # arrows on both ends
lwd = 2,   # thick line
)
# title
title(main = "Between-group variation\n(i.e., differences among group means)",
font.main = 1)
width <- 7
height <- 4
# params
mu <- c(-4, -.25, 3.5)
sig <- 2
# data
x <- seq(-3,3,.1)
x1 <- x*sig + mu[1]
x2 <- x*sig + mu[2]
x3 <- x*sig + mu[3]
y1 <- dnorm( x1, mu[1], sig )
y2 <- dnorm( x2, mu[2], sig )
y3 <- dnorm( x3, mu[3], sig )
# set up window
plot.new() # create graphics device
plot.window(xlim = c(-10,10), ylim = c(0,.25)) # define plot area
axis(side = 1, # axis located below
col = "gray20",  # coloured gray
at = c(-10,mu,10), # tick marks located at
labels = c("","group 1","group 2","group 3","")
)
# plot densities
lines(x1,y1, type = "l", col = "gray20")
lines(x2,y2, type = "l", col = "gray20")
lines(x3,y3, type = "l", col = "gray20")
# arrows
x <- 1.5
y <- .135
for (i in 1:3) {
arrows(
mu[i]-x,y, # from
mu[i]+x,y, # to
code = 3,  # arrows on both ends
lwd = 2,   # thick line
)  }
GrandMean <- mean(accSIM30$Accurate)
GrandMean
#this script is used for the inline coding in the lesson and, although you will want to run it so you can "feed" the objects into later script, there is no "lesson" relative to this lecture
GrandMean <- formattable::digits(GrandMean, 3)
GrandMean
library(tidyverse)
accSIM30 <- accSIM30 %>%
dplyr::mutate(m_dev = Accurate-mean(Accurate))
head(accSIM30)
mean(accSIM30$m_dev)
accSIM30 <- accSIM30 %>%
dplyr::mutate(m_devSQ = m_dev^2)
head(accSIM30)
SST <- sum(accSIM30$m_devSQ)
SST
#this script is used for the inline coding in the lesson and, although you will want to run it so you can "feed" the objects into later script, there is no "lesson" relative to this lecture
SST <- formattable::digits(SST,3)
SST
GroupMeans <- aggregate (Accurate ~ COND, accSIM30, mean)
GroupMeans
#this script is used for the inline coding in the lesson and, although you will want to run it so you can "feed" the objects into later script, there is no "lesson" relative to this lecture
ControlMean <- formattable::digits(GroupMeans$Accurate[1],3)
ControlMean
LowMean <- formattable::digits(GroupMeans$Accurate[2],3)
LowMean
HighMean <- formattable::digits(GroupMeans$Accurate[3],3)
HighMean
nGroup <- accSIM30 %>% count(COND)
nGroup
nControl <- nGroup$n[1]
nControl
nLow <- nGroup$n[2]
nLow
nHigh<- nGroup$n[3]
nHigh
#Calculated by using object names from our calculations
SSM <- nControl*(ControlMean - GrandMean)^2 + nLow*(LowMean - GrandMean)^2 + nHigh*(HighMean - GrandMean)^2
SSM
#calculated by specifying the actual values from our calculations
30*(1.756 - 1.603)^2 + 30*(1.900 - 1.603)^2 + 30*(1.153 - 1.603)^2
#Both result in the same
#this script is used for the inline coding in the lesson and, although you will want to run it so you can "feed" the objects into later script, there is no "lesson" relative to this lecture
SSM <- formattable::digits (SSM,3)
SSM
SDs <- aggregate (Accurate ~ COND, accSIM30, sd)
SDs
#this script is used for the inline coding in the lesson and,
#although you will want to run it so you can "feed" the objects into later script,
#there is no lesson relative to this lecture
sdControl <- formattable::digits(SDs$Accurate[1],3)
sdControl
sdLow <- formattable::digits(SDs$Accurate[2],3)
sdLow
sdHigh <- formattable::digits(SDs$Accurate[3],3)
sdHigh
#when squared, the standard deviation of the control group,
#hould equal the variance reported in the next chunk
sdControl^2
VARs <- aggregate (Accurate ~ COND, accSIM30, var)
VARs
#this script is used for the inline coding in the lesson and, although you will want to run it so you can "feed" the objects into later script, there is no "lesson" relative to this lecture
varControl <- formattable::digits(VARs$Accurate[1],3)
varControl
varLow <- formattable::digits(VARs$Accurate[2],3)
varLow
varHigh <- formattable::digits(VARs$Accurate[3],3)
varHigh
#Calculated by using object names from our calculations
SSR <- varControl*(nControl-1) + varLow*(nLow-1) + varHigh*(nHigh-1)
#Re-calculated by specifying the actual values from our calculations
SSR
0.212*(30-1) + 0.397*(30-1) + 0.434*(30-1)
#Both result in the same
#calculated with object names
SSM + SSR
#we name the function
#in parentheses we list data source
psych::describe(accSIM30$Accurate)
#It is unnecessary to create an object, but an object allows you to do cool stuff, like write it to a .csv file and use that as a basis for APA style tables
#In this script we can think "Accurate by COND" meaning that the descriptives for accuracy will be grouped by COND which is a categorical variable
#mat = TRUE presents the output in matrix (table) form
#digits = 3 rounds the output to 3 decimal places
#data = accSIM30 is a different (I think easier) way to identify the object that holds the dataframe
des.mat <- psych::describeBy (Accurate ~ COND, mat=TRUE, digits=3, data=accSIM30)
#Note. Recently my students and I have been having intermittent struggles with the describeBy function in the psych package. We have noticed that it is problematic when using .rds files and when using data directly imported from Qualtrics. If you are having similar difficulties, try uploading the .csv file and making the appropriate formatting changes.
#displays the matrix object that we just created
des.mat
#optional to write it to a .csv file
write.csv (des.mat, file="Table1.csv")
shapiro <- accSIM30 %>%
group_by(COND) %>%
rstatix::shapiro_test(Accurate)
shapiro
#this script is used for the inline coding in the lesson and, although you will want to run it so you can "feed" the objects into later script, there is no "lesson" relative to this lecture
swControl <- formattable::digits(shapiro$statistic[1],3)
swControl
swLow <- formattable::digits(shapiro$statistic[2],3)
swLow
swHigh <- formattable::digits(shapiro$statistic[3],3)
swHigh
swControlp <- formattable::digits(shapiro$p[1],3)
swControlp
swLowp <- formattable::digits(shapiro$p[2],3)
swLowp
swHighp <- formattable::digits(shapiro$p[3],3)
swHighp
#Our set up is similar:  Accurate by condition, followed by the object that holds the dataframe, followed by the instruction to center the analysis around the mean
levene <- car::leveneTest (Accurate ~ COND, accSIM30, center=mean)
levene
#this script is used for the inline coding in the lesson and, although you will want to run it so you can "feed" the objects into later script, there is no "lesson" relative to this lecture
df1levene<- formattable::digits(levene$Df[1],0)
df1levene
df2levene<- formattable::digits(levene$Df[2],0)
df2levene
Flevene <- formattable::digits(levene$"F value"[1],3)
Flevene
plevene <- formattable::digits(levene$"Pr(>F)"[1],3)
plevene
#the script looks familiar, "Accurate by Condition"
#DV ~ IV  I say, "DV by IV"
omnibus <- aov(Accurate ~ COND, data = accSIM30)
#prints the ANOVA output
summary (omnibus)
#this script is used for the inline coding in the lesson and, although you will want to run it so you can "feed" the objects into later script, there is no "lesson" relative to this lecture
df1omnibus<- formattable::digits(summary(omnibus)[[1]][1, "Df"],0)
df1omnibus
df2omnibus<- formattable::digits(summary(omnibus)[[1]][2, "Df"],0)
df2omnibus
SSMomnibus<- formattable::digits(summary(omnibus)[[1]][1, "Sum Sq"],3)
SSMomnibus
SSRomnibus<- formattable::digits(summary(omnibus)[[1]][2, "Sum Sq"],3)
SSRomnibus
SSTomnibus <- formattable::digits((SSMomnibus + SSRomnibus),3)
SSTomnibus
MSMomnibus<- formattable::digits(summary(omnibus)[[1]][1, "Mean Sq"],3)
MSMomnibus
MSRomnibus<- formattable::digits(summary(omnibus)[[1]][2, "Mean Sq"],3)
MSRomnibus
Fomnibus<- formattable::digits(summary(omnibus)[[1]][1, "F value"],3)
Fomnibus
pomnibus<- formattable::digits(summary(omnibus)[[1]][1, "Pr(>F)"],3)
pomnibus
names(omnibus)
model.tables (omnibus, "means")
plot(omnibus)
#Calculated using the object names
SSMomnibus / (SSMomnibus + SSRomnibus)
lsr::etaSquared(omnibus)
#this script is used for the inline coding in the lesson and, although you will want to run it so you can "feed" the objects into later script, there is no "lesson" relative to this lecture
etaSQomni <- formattable::digits(lsr::etaSquared(omnibus)[1, "eta.sq"],3)
etaSQomni
pairwise.t.test(accSIM30$Accurate, accSIM30$COND, p.adj = "none")
#can swap "bonf" or "holm" for p.adj
summary.lm(omnibus)
#Contrast1 compares Control against the combined effects of Low and High.
contrast1 <- c(-2,1,1)
#Contrast2 excludes Control; compares Low to High.
contrast2 <- c(0,-1,1)
#binding the contrasts together
contrasts(accSIM30$COND)<-cbind(contrast1, contrast2)
accSIM30$COND
#create a new object, the ANOVA looks the same, but it will now consider the contrasts (this is where order-of-operations matters)
accPlanned <- aov(Accurate ~ COND, data = accSIM30)
summary.lm(accPlanned)
contrasts(accSIM30$COND)<-cbind(c(-2,1,1), c(0,-1,1))
contrasts(accSIM30$COND)<-contr.poly(3)
accTrend<-aov(Accurate ~ COND, data = accSIM30)
summary.lm(accTrend)
oneway.test (Accurate ~ COND, data = accSIM30)
effectsize::eta2_to_f(.238)
pwr::pwr.anova.test (k = 3, f = .5589, sig.level = .05, power = .80)
pwr::pwr.anova.test (k = 3, f = .1, sig.level = .05, power = .80)
#table.number = 1 assigns a table number to the top of the table
#filename = "Table1.doc" writes the table to Microsoft Word and puts it in your project folder
apaTables::apa.1way.table(iv=COND, dv=Accurate, show.conf.interval = TRUE, data=accSIM30, table.number = 1, filename = "Table1.doc")
#calculating mean difference between control and hig
1.76 - 1.15
#calculating mean difference between low and high
1.90 - 1.15
#calculating mean difference between control and low
1.76 - 1.90
apaTables::apa.aov.table (omnibus, table.number = 2, filename = "Table2.doc")
gplots::plotmeans (formula = Accurate ~ COND, data = accSIM30, xlab = "Racial Loading Condition", ylab = "Accuracy of Confederate's Impression", n.label = FALSE)
