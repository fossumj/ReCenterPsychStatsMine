median(toy$toy, na.rm=TRUE)
quantile(toy$toy, probs = .50, na.rm=TRUE )
median (df$nAff, na.rm=TRUE)
quantile(df$nAff, probs = .50, na.rm=TRUE )
median (df$nAff, na.rm=TRUE)
quantile(df$nAff, probs = .50, na.rm=TRUE )
quantile(df$nAff, probs=c(.10, .20, .30, .40, .50, .60, .70, .80, .90))
quantile(df$nAff, probs = c(.25,.75) )
2.24 - 1.29
IQR(df$nAff, na.rm=TRUE)
#Dissecting the script,
#each variable is referenced by df_name$variable_name
toy$mean <- mean(toy$toy, na.rm=TRUE)
head(toy)#displays the first 6 rows of the data
toy$mdev <- toy$toy - toy$mean
head(toy)#displays the first 6 rows of the data
#Dissecting the script,
#Wrapping the sum and mean script in "round" and following with the desired decimal places, provides a rounde result.
round(sum(toy$mdev, na.rm=TRUE),3)
round(mean(toy$mdev, na.rm=TRUE),3)
#Dissecting the script,
#Wrapping the sum and mean script in "round" and following with the desired decimal places, provides a rounde result.
(sum(toy$mdev, na.rm=TRUE),3)
mean(toy$mdev, na.rm=TRUE)
#Dissecting the script,
#Wrapping the sum and mean script in "round" and following with the desired decimal places, provides a rounde result.
round(sum(toy$mdev, na.rm=TRUE),3)
round(mean(toy$mdev, na.rm=TRUE),3)
toy$abslt_m <- abs(toy$mdev)
head(toy)
round(mean(toy$abslt_m, na.rm=TRUE),3)
library(tidyverse)
df_nAff <- df%>%dplyr::select(nAff)
View(df_nAff)
df_nAff$mdevNA <- df_nAff$nAff - mean(df_nAff$nAff, na.rm=TRUE)
df_nAff$mdevNA <- df_nAff$nAff - mean(df_nAff$nAff, na.rm=TRUE)
df_nAff$abNAmdev <- abs(df_nAff$mdevNA)
head(df_nAff)
round(mean(df_nAff$abNAmdev, na.rm=TRUE),3)
toy$mdev2 <- (toy$mdev)*(toy$mdev)
toy$mdev2 <- (toy$mdev)*(toy$mdev)
sum(toy$mdev2, na.rm=TRUE)#sum of squared deviations
head(toy)
toy$mdev2 <- (toy$mdev)*(toy$mdev)
sum(toy$mdev2, na.rm=TRUE)#sum of squared deviations
toy$mdev2 <- (toy$mdev)*(toy$mdev)
sum(toy$mdev2, na.rm=TRUE)#sum of squared deviations
9.2/(5-1)#calculated with the previously obtained values
toy <- na.omit(toy)
sum(toy$mdev2, na.rm=TRUE)/((nrow(toy)-1))#variance
toy <- na.omit(toy)
sum(toy$mdev2, na.rm=TRUE)/((nrow(toy)-1))#variance
9.2/(5-1)#calculated with the previously obtained values
#to obtain the "correct" calculation by using each of these individual R commands, we need to have non-missing data
toy <- na.omit(toy)
sum(toy$mdev2, na.rm=TRUE)/((nrow(toy)-1))#variance
mean(toy$toy, na.rm=TRUE)
var(toy$toy, na.rm=TRUE)
View(df_nAff)
df_nAff$NAmd2 <- (df_nAff$mdevNA)*(df_nAff$mdevNA)
head(df_nAff)
sum(df_nAff$NAmd2, na.rm=TRUE)#sum of squared deviations
283.44/(713-1)
283.44/(713-1)
sum(df_nAff$NAmd2, na.rm=TRUE)/((nrow(df_nAff)-1))#variance
283.44/(713-1)
sum(df_nAff$NAmd2, na.rm=TRUE)/((nrow(df_nAff)-1))#variance
var(df_nAff$nAff)
#six steps wrapped into 1
toy$mdev <- toy$toy - mean(toy$toy, na.rm=TRUE)
toy$mdev2 <- (toy$mdev)*(toy$mdev)
#I can save the variance calculation as an object for later use
toy_var <- sum(toy$mdev2)/(nrow(toy)-1)
#checking work with the variance function
var(toy$toy)
#grabbing the mean for quick reference
mean(toy$toy)
toy_var <- sum(toy$mdev2)/(nrow(toy)-1)
#checking work with the variance function
var(toy$toy)
#I can save the variance calculation as an object for later use
toy_var <- sum(toy$mdev2)/(nrow(toy)-1)
#checking work with the variance function
var(toy$toy)
#grabbing the mean for quick reference
mean(toy$toy)
#below the "toy_var" object was created in the prior step
sqrt(toy_var)
#checking work with the R function to calculate standard deviation
sd(toy$toy)
#six steps wrapped into 1
toy$mdev <- toy$toy - mean(toy$toy, na.rm=TRUE)
toy$mdev2 <- (toy$mdev)*(toy$mdev)
#I can save the variance calculation as an object for later use
toy_var <- sum(toy$mdev2)/(nrow(toy)-1)
#checking work with the variance function
var(toy$toy)
#grabbing the mean for quick reference
mean(toy$toy)
#below the "toy_var" object was created in the prior step
sqrt(toy_var)
#checking work with the R function to calculate standard deviation
sd(toy$toy)
#six steps wrapped into 1
df_nAff$mdevNA <- df_nAff$nAff - mean(df_nAff$nAff, na.rm=TRUE)
df_nAff$NAmd2 <- (df_nAff$mdevNA)*(df_nAff$mdevNA)
#I can save the variance calculation as an object for later use
nAff_var <- sum(df_nAff$NAmd2)/(nrow(df)-1)
#checking work with the variance function
var(df_nAff$nAff)
#below the "toy_var" object was created in the prior step
sqrt(nAff_var)
#checking work with the R function to calculate standard deviation
sd(df_nAff$nAff)
#grabbing the mean for quick reference
mean(df_nAff$nAff)
#below the "toy_var" object was created in the prior step
sqrt(nAff_var)
#checking work with the R function to calculate standard deviation
sd(df_nAff$nAff)
#curve(dbeta(x,10,2), xlim=c(0,1), lwd=3)
curve(dbeta(x,10,10), xlim=c(0,1), lwd=3)
curve(dbeta(x,5, 5), add=T, col='red',lwd=3)
curve(dbeta(x,2,2), add=T, col='blue',lwd=3)
legend(par('usr')[2], par('usr')[4], xjust=1,
c('leptokurtic', 'mesokurtic', 'platykurtic'),
lwd=c(3,3,1), lty=1,
col=c(par('fg'),'red','green'))
title("Kurtosis")
curve(dbeta(x,10,10), xlim=c(0,1), lwd=3)
curve(dbeta(x,2, 5), add=T, col='red',lwd=3)
curve(dbeta(x,5,2), add=T, col='blue',lwd=3)
legend(par('usr')[2], par('usr')[4], xjust=1,
c('normal', 'positive skew', 'negative skew'),
lwd=c(3,3,1), lty=1,
col=c(par('fg'),'red','green'))
title("Skew")
#I have opened the tidyverse library so that I can use the pipe
library(tidyverse)
df_3vars <- df%>%dplyr::select(nAff, mAggr, drProb)
View(df_3vars)
psych::describe(df_3vars)
LuiDescripts <- psych::describe(df_3vars)
View(LuiDescripts)
write.csv (LuiDescripts, file="LuiDescripts.csv")
LuiDescripts <- psych::describe(df_3vars)
write.csv (LuiDescripts, file="LuiDescripts.csv")
#Once you create an object, the result won't automatically display; to see it simply type the name of the object
LuiDescripts
#using the dplyr package to select the two variables in this tiny df
df4corr <- df%>%dplyr::select(nAff, mAggr)
#just in case it turned off, I'm reopening tidyverse so that I can use the pipe ($>$)
library(tidyverse)
#using the dplyr package to select the two variables in this tiny df
df4corr <- df%>%dplyr::select(nAff, mAggr)
#displaying the first 6 rows of df4corr ("dataframe for correlations" -- I made this up)
head(df4corr)
View(df4corr)
#calculating the mean deviation for negative affect
df4corr$MDnAff <- df4corr$nAff - mean(df4corr$nAff)
#calculating the mean deviation for microaggressions
df4corr$MDmAggr <- df4corr$mAggr - mean(df4corr$mAggr)
#displaying the first 6 rows of df4corr
head(df4corr)
#Creating a crossproduct variabl by multiplying negative affect by psych distress
df4corr$crossproductXY <- df4corr$MDnAff * df4corr$MDmAggr
#displaying the first 6 rows of df4corr
head(df4corr)
sum(df4corr$crossproductXY)
#I have created the object "cov" so I can use it in a calculation, later
cov <- 1/(nrow(df4corr) - 1)* sum(df4corr$crossproductXY)
#Because I created an object, R markdown won't automatically display it; I have to request it by listing it
cov
cov/(sd(df4corr$nAff)*sd(df4corr$mAggr))
cor.test(df4corr$nAff, df4corr$mAggr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen=999)#eliminates scientific notation
cor.test(df4corr$nAff, df4corr$mAggr)
#in the code below, psych points to the package
#pairs.panels points to the function
#we simply add the name of the df; if you want fewer variables than that are in the df, you may wish to create a smaller df
#adding the pch command is optional and produces a finer resolution
psych::pairs.panels(df_3vars, pch = ".")
#in the code below, psych points to the package
#pairs.panels points to the function
#we simply add the name of the df; if you want fewer variables than that are in the df, you may wish to create a smaller df
#adding the pch command is optional and produces a finer resolution
psych::pairs.panels(df_3vars, pch = ".")
#the apa.cor.table function removes any categorical variables that might be in the df
Table1_Cor <- apaTables::apa.cor.table(df_3vars, filename = "Table1_Cor.doc", table.number = 1, show.conf.interval = FALSE, landscape = TRUE)
#swap in this command to see it in the R Markdown file
print(Table1_Cor)
ggpubr::gghistogram(dfOneSample, x = "PhysMins",  add = "mean",  rug = TRUE, color = "#993366")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen=999)#eliminates scientific notation
#will install the package if not already installed
#if(!require(psych)){install.packages("psych")}
#if(!require(faux)){install.packages("faux")}
#if(!require(tidyverse)){install.packages("tidyverse")}
#if(!require(dplyr)){install.packages("dplyr")}
#if(!require(lsr)){install.packages("lsr")}
#if(!require(ggpubr)){install.packages("ggpubr")}
#http://rstudio-pubs-static.s3.amazonaws.com/78857_86c2403ca9c146ba8fcdcda79c3f4738.html
par(mfrow=c(1,3))
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(-1,1,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(-1,x,1),c(0,y,0),col="#FF99CC")
text(0,0.1,"68.3%")
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(-2,2,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(-2,x,2),c(0,y,0),col="#cc99cc")
text(0,0.1,"95.4%")
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(-3,3,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(-3,x,3),c(0,y,0),col="#993366")
text(0,0.1,"99.7%")
#https://r-charts.com/distribution/histogram-curves/
set.seed(220821)
PhysTime <- data.frame(minutes = rnorm(200, mean=10, sd=2))
psych::describe(PhysTime$minutes)
9.9 - 1*(2)
9.9 + 1*(2)
9.9 - 2*(2)
9.9 + 2*(2)
9.9 - 3*(2)
9.9 + 3*(2)
(9.9-9.9)/2 #for 9.9 minutes
#http://rstudio-pubs-static.s3.amazonaws.com/78857_86c2403ca9c146ba8fcdcda79c3f4738.html
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(-3,0,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(-3,x,0),c(0,y,0),col="#993366")
arrows(.3,.2,0,0,length=.15)
text(.5,0.22,"z = 0.000")
text(-.75,0.1,"0.5000 or 50%")
text(1,0.1,"0.5000 or 50%")
pnorm(0, mean=0, sd=1)
pnorm(9.9, mean=9.9, sd=2)
#calculating the z-score
(5-9.9)/2 #for 5 minutes
pnorm(-2.45, mean=0, sd=1)
pnorm(5, mean=9.9, sd=2)
#http://rstudio-pubs-static.s3.amazonaws.com/78857_86c2403ca9c146ba8fcdcda79c3f4738.html
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(-3,-2.45,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(-3,x,-2.45),c(0,y,0),col="#993366")
arrows(-2.45,.2,-2.45,0,length=.15)
text(-2.45,0.22,"z = -2.45")
text(-2.3,0.1,"0.007 or .7%")
text(0,0.1,"0.993 or 99.3%")
(12-9.9)/2 #for 12 minutes
1-.8531
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(1.05,3,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(1.05,x,3),c(0,y,0),col="#993366")
arrows(.5,.2,1.05,0,length=.15)
text(.5,0.22,"z = 1.05")
text(-1,0.1,".8531 or 85%")
text(1.6,0.1,".1469 or 15%")
PhysTime$zMinutes <- (PhysTime$minutes - mean(PhysTime$minutes))/sd(PhysTime$minutes)
head(PhysTime)
apaTables::apa.cor.table(PhysTime)
par(mfrow=c(1,3))
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(-1.96,1.96,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(-1.96,x,1.96),c(0,y,0),col="#CCCCCC")
text(-2.3,0.1,"-1.96")
text(2.2,0.1,"1.96")
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(-1.64,3,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(-1.64,x,3),c(0,y,0),col="#CCCCCC")
text(-1.75,0.2,"-1.64")
psych::describe(PhysTime$minutes)
(9.9 - 10.5)/(2/sqrt(200))
pnorm(-4.24, mean=9.9, sd=2)
#Setting the "random" seed ensures that everyone gets the same result, every time they rerun the analysis.
#My personal practice is to create a random seed that represents the day I write up the problem (in this case August, 15, 2022)
#When the Suggestions for Practice invite you to "change the random seed," simply change this number to anything you like (maybe your birthday or today's date)
set.seed(220822)
dfOneSample <- data.frame(PhysMins = rnorm(33, mean=10, sd=2.5))
head(dfOneSample)
str(dfOneSample)
#writing the simulated data as a .csv
#write.table(dfOneSample, file = "dfOneSample.csv", sep = ',', col.names=TRUE, row.names=FALSE)
#at this point you could clear your environment and then bring the data back in as a .csv
#reading the data back in as a .csv file
#dfOneSample<- read.csv ('dfOneSample.csv', header = TRUE)
#saveRDS(dfOneSample, 'dfOneSample.rds')
#dfOneSample <- readRDS('dfOneSample.rds')
ggpubr::gghistogram(dfOneSample, x = "PhysMins",  add = "mean",  rug = TRUE, color = "#993366")
#https://r-charts.com/distribution/histogram-curves/
set.seed(220821)
PhysTime <- data.frame(minutes = rnorm(200, mean=10, sd=2))
View(PhysTime)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen=999)#eliminates scientific notation
#will install the package if not already installed
#if(!require(psych)){install.packages("psych")}
#if(!require(faux)){install.packages("faux")}
#if(!require(tidyverse)){install.packages("tidyverse")}
#if(!require(dplyr)){install.packages("dplyr")}
#if(!require(lsr)){install.packages("lsr")}
#if(!require(ggpubr)){install.packages("ggpubr")}
#http://rstudio-pubs-static.s3.amazonaws.com/78857_86c2403ca9c146ba8fcdcda79c3f4738.html
par(mfrow=c(1,3))
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(-1,1,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(-1,x,1),c(0,y,0),col="#FF99CC")
text(0,0.1,"68.3%")
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(-2,2,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(-2,x,2),c(0,y,0),col="#cc99cc")
text(0,0.1,"95.4%")
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(-3,3,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(-3,x,3),c(0,y,0),col="#993366")
text(0,0.1,"99.7%")
#https://r-charts.com/distribution/histogram-curves/
set.seed(220821)
PhysTime <- data.frame(minutes = rnorm(200, mean=10, sd=2))
psych::describe(PhysTime$minutes)
9.9 - 1*(2)
9.9 + 1*(2)
9.9 - 2*(2)
9.9 + 2*(2)
9.9 - 3*(2)
9.9 + 3*(2)
(9.9-9.9)/2 #for 9.9 minutes
#http://rstudio-pubs-static.s3.amazonaws.com/78857_86c2403ca9c146ba8fcdcda79c3f4738.html
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(-3,0,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(-3,x,0),c(0,y,0),col="#993366")
arrows(.3,.2,0,0,length=.15)
text(.5,0.22,"z = 0.000")
text(-.75,0.1,"0.5000 or 50%")
text(1,0.1,"0.5000 or 50%")
(9.9-9.9)/2 #for 9.9 minutes
pnorm(0, mean=0, sd=1)
pnorm(9.9, mean=9.9, sd=2)
pnorm(0, mean=0, sd=1)
pnorm(9.9, mean=9.9, sd=2)
#calculating the z-score
(5-9.9)/2 #for 5 minutes
pnorm(-2.45, mean=0, sd=1)
pnorm(-2.45, mean=0, sd=1)
pnorm(5, mean=9.9, sd=2)
#http://rstudio-pubs-static.s3.amazonaws.com/78857_86c2403ca9c146ba8fcdcda79c3f4738.html
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(-3,-2.45,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(-3,x,-2.45),c(0,y,0),col="#993366")
arrows(-2.45,.2,-2.45,0,length=.15)
text(-2.45,0.22,"z = -2.45")
text(-2.3,0.1,"0.007 or .7%")
text(0,0.1,"0.993 or 99.3%")
(12-9.9)/2 #for 12 minutes
1-.8531
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(1.05,3,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(1.05,x,3),c(0,y,0),col="#993366")
arrows(.5,.2,1.05,0,length=.15)
text(.5,0.22,"z = 1.05")
text(-1,0.1,".8531 or 85%")
text(1.6,0.1,".1469 or 15%")
PhysTime$zMinutes <- (PhysTime$minutes - mean(PhysTime$minutes))/sd(PhysTime$minutes)
head(PhysTime)
PhysTime$zMinutes <- (PhysTime$minutes - mean(PhysTime$minutes))/sd(PhysTime$minutes)
head(PhysTime)
View(PhysTime)
apaTables::apa.cor.table(PhysTime)
psych::describe(PhysTime$minutes)
(9.9 - 10.5)/(2/sqrt(200))
par(mfrow=c(1,3))
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(-1.96,1.96,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(-1.96,x,1.96),c(0,y,0),col="#CCCCCC")
text(-2.3,0.1,"-1.96")
text(2.2,0.1,"1.96")
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=1)
plot(x,y,type="l")
x=seq(-1.64,3,length=100)
y=dnorm(x,mean=0,sd=1)
polygon(c(-1.64,x,3),c(0,y,0),col="#CCCCCC")
text(-1.75,0.2,"-1.64")
pnorm(-4.24, mean=9.9, sd=2)
#Setting the "random" seed ensures that everyone gets the same result, every time they rerun the analysis.
#My personal practice is to create a random seed that represents the day I write up the problem (in this case August, 15, 2022)
#When the Suggestions for Practice invite you to "change the random seed," simply change this number to anything you like (maybe your birthday or today's date)
set.seed(220822)
dfOneSample <- data.frame(PhysMins = rnorm(33, mean=10, sd=2.5))
head(dfOneSample)
View(dfOneSample)
str(dfOneSample)
write.table(dfOneSample, file = "dfOneSample.csv", sep = ',', col.names=TRUE, row.names=FALSE)
#writing the simulated data as a .csv
#write.table(dfOneSample, file = "dfOneSample.csv", sep = ',', col.names=TRUE, row.names=FALSE)
#at this point you could clear your environment and then bring the data back in as a .csv
#reading the data back in as a .csv file
dfOneSample<- read.csv ('dfOneSample.csv', header = TRUE)
View(dfOneSample)
View(dfOneSample)
str(dfOneSample)
saveRDS(dfOneSample, 'dfOneSample.rds')
#saveRDS(dfOneSample, 'dfOneSample.rds')
dfOneSample <- readRDS('dfOneSample.rds')
#saveRDS(dfOneSample, 'dfOneSample.rds')
dfOneSample <- readRDS('dfOneSample.rds')
View(dfOneSample)
View(dfOneSample)
ggpubr::gghistogram(dfOneSample, x = "PhysMins",  add = "mean",  rug = TRUE, color = "#993366")
ggpubr::ggboxplot(dfOneSample$PhysMins,
ylab = "Seconds with Patient", xlab = FALSE, add="jitter"
)
psych::describe(dfOneSample$PhysMins)
(10.01 - 1.23)/(2.7/sqrt(33))
qt(p=.05/2, df=33,lower.tail=FALSE)
qt(p=.05/2, df=33,lower.tail=FALSE)
(10.01) - ((2.0369)*(2.7/sqrt(33)))
(10.01) + ((2.0369)*(2.7/sqrt(33)))
#First formula
(10.01 - 1.23)/2.7
#Second formula
18.68047/sqrt(33)
#First formula
(10.01 - 1.23)/2.7
#Second formula
18.68047/sqrt(33)
lsr::oneSampleTTest(x=dfOneSample$PhysMins, mu=1.23)
ggpubr::ggboxplot(dfOneSample$PhysMins,
ylab = "Physician Minutes", xlab = FALSE, add="jitter", title = "Figure 1. Physician Time with Patients (in minutes)"
)
pwr::pwr.t.test(d= (10.01-1.23)/2.7,n = 33, power=NULL,sig.level=0.05,type="one.sample",alternative="two.sided")
pwr::pwr.t.test(d= (10.01-1.23)/2.7, n = NULL, power=0.8,sig.level=0.05,type="one.sample",alternative="two.sided")
set.seed(220822)
rdfOneSample <- data.frame(rPhysMins = rnorm(4, mean=10, sd=2.5))
head(rdfOneSample)
lsr::oneSampleTTest(x=rdfOneSample$rPhysMins, mu=1.23)
set.seed(220822)
rdfOneSample <- data.frame(rPhysMins = rnorm(3, mean=10, sd=2.5))
head(rdfOneSample)
lsr::oneSampleTTest(x=rdfOneSample$rPhysMins, mu=1.23)
#saveRDS(dfOneSample, 'dfOneSample.rds')
dfOneSample <- readRDS('dfOneSample.rds')
ggpubr::gghistogram(dfOneSample, x = "PhysMins",  add = "mean",  rug = TRUE, color = "#993366")
ggpubr::ggboxplot(dfOneSample$PhysMins,
ylab = "Minutes with Patient", xlab = FALSE, add="jitter"
)
psych::describe(dfOneSample$PhysMins)
(10.01 - 1.23)/(2.7/sqrt(33))
qt(p=.05/2, df=32,lower.tail=FALSE)
qt(p=.05/2, df=32,lower.tail=FALSE)
(10.01) - ((2.0369)*(2.7/sqrt(33)))
(10.01) + ((2.0369)*(2.7/sqrt(33)))
#First formula
(10.01 - 1.23)/2.7
#Second formula
18.68047/sqrt(33)
#First formula
(10.01 - 1.23)/2.7
#Second formula
18.68047/sqrt(33)
lsr::oneSampleTTest(x=dfOneSample$PhysMins, mu=1.23)
ggpubr::ggboxplot(dfOneSample$PhysMins,
ylab = "Physician Minutes", xlab = FALSE, add="jitter", title = "Figure 1. Physician Time with Patients (in minutes)"
)
