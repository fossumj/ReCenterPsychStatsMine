```{r include=FALSE}
options(scipen=999)#eliminates scientific notation
```
## Homeworked Example

[Screencast Link](https://youtu.be/eRCDNibARtg)

For more information about the data used in this homeworked example, please refer to the description and codebook located at the end of the [introduction](ReCintro).

### Working the Problem with R and R Packages

#### Narrate the research vignette, describing the IV, DV, and COV {-} 

I want to ask the question, what are the effects of intentional recentering on students' evaluations of socially responsive pedagogy in the multivariate (last) course as a function of centering status (i.e., pre versus re), controlling for the socially responsive evaluations in the ANOVA (first) course:

* Continuous DV: SRPed (socially responsive pedagogy) in the multivariate (last) class
* Between-subjects factor: recentering status of the class (Pre, Re)
* Covariate: SRPed in the ANOVA (first) class


*If you wanted to use this example and dataset as a basis for a homework assignment, you could choose a different dependent variable. I chose the socially responsive pedagogy subscale. Two other subscales include traditional pedagogy and valued by the student.*

#### Simulate (or import) and format data {-}

First I import the larger dataset.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
big <- readRDS("ReC.rds")
```

The SRPed (socially responsive pedagogy) variable is an average of the items on that scale. I will first create that variable.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
#Creates a list of the variables that belong to that scale
SRPed_vars <- c('InclusvClassrm', 'EquitableEval','MultPerspectives', 'DEIintegration')

#Calculates a mean if at least 75% of the items are non-missing; adjusts the calculating when there is missingness
big$SRPed <- sjstats::mean_n(big[, SRPed_vars], .75)

#if the scoring script won't run, try this one:
#big$SRPed <- sjstats::mean_n(big[, ..SRPed_vars], .75)
```

Let's trim it to just the variables of interest.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
ANCOVA_df <- (dplyr::select (big, deID, Course, Centering, SRPed))
```

And further filter so that there are just evaluations of ANOVA and multivariate courses.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
ANCOVA_df <- subset(ANCOVA_df, Course == "ANOVA" | Course == "Multivariate") #multiple conditions
```

I want the course variable to be factor that is ordered by its sequence:  ANOVA, multivariate.

I want the centering variable to be ordered:  Pre, Re

```{r }
str(ANCOVA_df)
```
Because R's default is to order alphabetically, the centering variable is correct. I just need to change the course variable.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
ANCOVA_df$Course <- factor(ANCOVA_df$Course, levels = c("ANOVA", "Multivariate"))
str(ANCOVA_df)
```
After checking the structure again, both are correct.

My data is in the long (person-period) form. For this particular ANOVA I need it to be in the wide (person level) form.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
ANCOVA_wide<- reshape2::dcast(data = ANCOVA_df, formula = deID + Centering ~ Course, value.var = "SRPed")
# before restructuring a second variable, rename the first variable
ANCOVA_wide <- dplyr::rename(ANCOVA_wide, SRPed_ANV = "ANOVA", SRPed_MLTV = "Multivariate")

str(ANCOVA_wide)
head(ANCOVA_wide)
```
The *head* function shows that the multivariate scores are missing. This design still has missingness for (a) some students who took ANOVA but haven't yet had multivariate and (b) others who may have skipped completing course evaluations. I'll take care of that next by requiring rows to have non-missing data. 

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
ANCOVA_wide <- na.omit(ANCOVA_wide)
```


#### Evaluate statistical assumptions {-}

**Is there a linear relationship between the covariate and outcome at each level of the grouping variable?"**

This would mean that there is linearity between the evaluation in the first course (covariate/ANOVA) and last course (outcome/Multivariate) at each level of the independent variable (Centering status).

We can get a visual of this with a scatterplot (with regression lines) between the covariae and outcome.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
library(ggplot2)
ggpubr::ggscatter(ANCOVA_wide, x = "SRPed_ANV", y = "SRPed_MLTV", color = "Centering", add = "reg.line") + ggpubr::stat_regline_equation(aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~~"), color = Centering))
```

The plot looks a little funny. This is likely because there are no values below 3(ish) for ANOVA when courses were re-centered. Although we are looking for a linear relationship, the angled lines suggest there could be an interaction effect. The previous lesson (when we included all three courses [ANOVA, psychometrics, multivariate]) showed that there was. Spoiler alert -- mixed design ANOVA is a better analysis for this question, but the data does allow me (statistically) to use it for a homework demonstration.

**Are the regression lines formed by the covariate and the outcome variable the same for each group?**

This would mean that there is no interaction between the outcome and covariate.  We can test this with an ANOVA model that specifies an interaction.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
library(tidyverse)
ANCOVA_wide %>%
  rstatix::anova_test(SRPed_MLTV ~Centering*SRPed_ANV)
```
Curiously, the interaction term was not statistically significant $(F[1, 71] = 1.975, p = 0.164)$. This non-violation of the homogeneity of slopes assumption supports the use of ANCOVA.

**Are the model residuals normally distributed and equal across groups?**

First, I create a linear regression model
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
SRPed_mod <- lm(SRPed_MLTV ~ SRPed_ANV + Centering, data = ANCOVA_wide) 
```

I will use *broom::augment()* to add fitted values and residuals to the model I just created.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
SRPed_mod_metrics <- broom::augment(SRPed_mod)
head(SRPed_mod_metrics)
```

I can now assess the normality of residuals with the Shapiro-Wilk test.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
rstatix::shapiro_test(SRPed_mod_metrics$.resid)
```

The Shapiro-Wilk test suggested that our residuals are not statistically significantly different from a normal distribution $(W = 0.972, p = 0.101)$.

ANCOVA further presumes that the variances of the residuals is equal for all groups. I can check this with the Levene's test.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)} 
SRPed_mod_metrics%>%
    rstatix::levene_test(.resid ~ Centering)
```
A non-significant Levene's test indicated no violation of the homogeneity of the residual variances for the groups $(F[1, 73] = 2.675, p = 0.106)$.


**Is there evidence of outliers?  Are they extreme?**

I can identify outliers by examining the standardized (or studentized) residuals. These are interpreted as the number of standard errors away from the regression line.

```{r}
SRPed_mod_metrics %>%
  filter(abs(.std.resid) > 3) %>%
           as.data.frame()
```

No outliers were identified.

Here's write-up of what I've done so far:

>A one-way analysis of covariance (ANCOVA) was conducted. The independent variable, centering stage, had two levels: pre-centered, re-centered. The dependent variable was students' evaluation of socially responsive pedagogy during the last statistics course (multivariate) and the covariate was the students' evaluation of the same variable during the first statistics class (ANOVA). 

>A preliminary analysis evaluating the homogeneity-of-slopes assumption indicated that the relationship between the covariate and the dependent variable did not differ significantly as a function of the independent variable, $(F[1, 71] = 1.975, p = 0.164)$. Further, the non-significant Shapiro-Wilk test of normality on the model residuals $(W = 0.972, p = 0.101)$ indicated that the dependent variable was not statistically significantly different from a normal distribution and no outliers were identified. A non-significant Leveneâ€™s test indicated no violation of the homogeneity of the residual variances for all groups $(F[1, 73] = 2.675, p = 0.106)$.


#### Conduct omnibus ANOVA (w effect size) {-}

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
ANCOVA_mod <- ANCOVA_wide %>%
    rstatix::anova_test(SRPed_MLTV ~ SRPed_ANV + Centering)
rstatix::get_anova_table(ANCOVA_mod)
```
>There was a significant effect of the evaluation of socially responsive pedagogy at the first course (ANOVA) on the same rating at the last course $(F [1,72] = 39.696, p < .001, \eta^2 = 0.355)$ as well as a statistically significant effect of recentering on evaluations of socially responsive pedagogy during the last class $(F [1,72]) = 10.304, p = 0.002, \eta^2 = 0.125)$. Considering that we interpret values $eta^2$ values  of .01, .06, and .14 to be small, medium, and large it appears that both the covariate and independent variable had substantial effects on the results.

#### Conduct one set of follow-up tests; narrate your choice {-}

Because this design has only two levels (pre-centered, re-centered), follow-up tests will not tell us any more information. However, investigating the covariate-adjusted mean is useful.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
emmeans_MLTV <- ANCOVA_wide%>%
  rstatix::emmeans_test(SRPed_MLTV ~ Centering, covariate = SRPed_ANV, p.adjust.method = "none")
emmeans_MLTV
```
Not surprisingly (since this single pairwise comparison is redundant with the omnibus ANCOVA), results suggest a statistically significant difference between the pre- and re-centered stages in the multivariate class.

With this script I can obtain the covariate-adjusted (i.e., estimated marginal) means.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
emmeans_list <- rstatix::get_emmeans(emmeans_MLTV)
emmeans_list
```
We can compare these to the  unadjusted means:

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
descripts_means <- psych::describeBy(SRPed_MLTV ~ Centering, data = ANCOVA_wide, mat=TRUE, digits=6)
descripts_means
```

While the differences are minor, they do exist.

#### Describe approach for managing Type I error {-}  

Because we only needed to conduct the omnibus, there was no additional control of Type I error.

#### APA style results with table(s) and figure {-}

>A one-way analysis of covariance (ANCOVA) was conducted. The independent variable, centering stage, had two levels: pre-centered, re-centered. The dependent variable was students' evaluation of socially responsive pedagogy during the last statistics course (multivariate) and the covariate was the students' evaluation of the same variable during the first statistics class (ANOVA). 

>A preliminary analysis evaluating the homogeneity-of-slopes assumption indicated that the relationship between the covariate and the dependent variable did not differ significantly as a function of the independent variable, $(F[1, 71] = 1.975, p = 0.100)$. Further, the non-significant Shapiro-Wilk test of normality on the model residuals $(W = 0.972, p = 0.101)$ indicated that the dependent variable was not statistically significantly different from a normal distribution and no outliers were identified.    A non-significant Leveneâ€™s test indicated no violation of the homogeneity of the residual variances for all groups $(F[1, 73] = 2.675, p = 0.106)$.

>There was a significant effect of the evaluation of socially responsive pedagogy at the first course (ANOVA) on the same rating at the last course $(F [1,72] = 39.696, p < .001, \eta^2 = 0.355)$ as well as a statistically significant effect of recentering on evaluations of socially responsive pedagogy during the last class $(F]1,72) = 10.304, p = 0.002, \eta^2 = 0.125)$. Considering that we interpret values $eta^2$ values  of .01, .06, and .14 to be small, medium, and large it appears that both the covariate and independent variable had substantial effects on the results. As illustrated in Figure 1, results suggested that those in the multivariate condition had more favorable ratings of socially responsive pedagogy than those in the ANOVA class. Table 1 provides unadjusted and covariate-adjusted means for the dependent variable.


In the case of ANCOVA, a table that compares unadjusted and covariate-adjusted means can be helpful. The lesson contains some script to export data. I will create a table to demonstrate how this might work:

|Table 1
|:--------------------------------------------------|
|Unadjusted and Covariate-Adjusted Descriptive Statistics  

|Centering      |Unadjusted     |Covariate-Adjusted
|:--------------|:-------------:|:-----------------:|

|               |*M*      |*SD*  |*EMM*      |*SE* 
|:--------------|:-------:|:----:|:---------:|:----:|
|Pre-centered   |4.381277	|0.633 |4.381639	 |0.067 |
|Re-centered    |4.732143	|0.425 |4.731534	 |0.086 |


And now a figure:

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
emmeans_MLTV <- emmeans_MLTV %>%
    rstatix::add_xy_position(x = "Centering", fun = "mean_se")
ggpubr::ggline(rstatix::get_emmeans(emmeans_MLTV), x = "Centering", y = "emmean", title = "Figure 1. SRPed Ratings as a Function of Centering, Controlling for Earlier Ratings") +
    geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
    ggpubr::stat_pvalue_manual(emmeans_MLTV, hide.ns = TRUE, tip.length = 0.02, , y.position = c(5.0))
```
