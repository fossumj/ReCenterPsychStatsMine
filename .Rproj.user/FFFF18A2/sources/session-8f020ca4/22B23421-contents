```{r include = FALSE}
options(scipen=999)
```

## Homeworked Example

[Screencast Link]()

For more information about the data used in this homeworked example, please refer to the description and codebook located at the end of the [introduction](ReCintro).

### Working the Problem with R and R Packages

#### Narrate the research vignette, describing the IV and DV. Miniminally, the data should allow the analysis of a 2 x 3 (or 3 X 2) design. At least one of the problems you work should have a significant interaction effect so that follow-up is required.

I want to ask the question, do course evaluation ratings for the traditional pedagogy dimension differ for students in the ANOVA class as a function of:

* **Stage** in the transition
  - STABLE:  2017 represents the last year of "stability during the old way" when we taught with SPSS and during the 2nd year of the doctoral programs.
  - TRANSITION:  2018 & 2019 represent the transition to R, when the classes were 30% larger because each of the IOP and CPY departments were transitioning to the 1st year (they did it separately, so as not to double the classes)
  - RESETTLED:  2020 & 2021 represent the "resettled" phase where the transition to R was fairly complete and the class size returned to normal because the classes were offered in the first year.
* **Department** 
  - CPY: Clinical Psychology
  - ORG: Industrial-Organizational Psychology

*If you wanted to use this example and dataset as a basis for a homework assignment, you could create a different subset of data. I worked the example for students taking the ANOVA class. You could choose multivariate or psychometrics. You could also choose a different dependent variable. I chose the traditional pedagogy subscale. Two other subscales include socially responsive pedagogy and valued by the student.*

#### Simulate (or import) and format data.

```{r}
big <- readRDS("ReC.rds")
```

Let's first create the "Stage" variable that represents the three levels of transition.  The ProgramYear variable contains the information I need, but the factor labels are not intuitive. Let me remap them.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
big$Stage <- plyr::mapvalues(big$ProgramYear, from = c("Second", "Transition", "First"), to = c("Stable", "Transition", "Resettled"))
```

Let's check the structure:
```{r}
str(big$Stage)
```

The TradPed (traditional pedagogy) variable is an average of the items on that scale. I will first create that variable.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
#Creates a list of the variables that belong to that scale
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')

#Calculates a mean if at least 75% of the items are non-missing; adjusts the calculating when there is missingness
big$TradPed <- sjstats::mean_n(big[, TradPed_vars], .75)

#if the scoring script won't run, try this one:
#big$TradPed <- sjstats::mean_n(big[, ..TradPed_vars], .75)
```

Each student in the dataset could contribute up to three course evaluations (i.e., one each for ANOVA, multivariate, psychometrics). Including all three would introduce *dependency* into the dataset and violate the assumption of independence. With our variables properly formatted let's create a subset with just the students who took ANOVA. 
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
TwoWay_df <- subset(big, Course == "ANOVA") 
```

Next, let's trim it to just the variables we need.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
TwoWay_df <-(dplyr::select(TwoWay_df, Stage, Dept, TradPed))
```

Although we would handle missing data more carefully in a "real study," I will delete all cases with any missingness. This will prevent problems in the hand-calculations section, later (and keep the two sets of results more similar).

```{r}
df <- na.omit(TwoWay_df)
```

Before we continue, this data has a hiccup that makes it less than ideal for a 2 x 3 ANOVA. In 2017 everyone enrolled in the CPY section of the course. That is, there was no distinction between CPY and ORG students.  In this dataset I do not have another variable with three levels.  I will recode some data which MAKES THE STORY UNTRUE, but will allow me to demo 2-way ANOVA (sighhhh). For your homework, you are very welcome to engage in such practices (it's actually good for learning!) however, we would never do so in the analysis of real data. 

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
TwoWay_df <- na.omit(TwoWay_df) #the next operation required non-missing data
TwoWay_df[TwoWay_df$Stage == "Stable" & TwoWay_df$TradPed < 4.3, "Dept"]<- "ORG"
```

Although the homework assignment doesn't require it, I think it's useful to create a figure that shows what I intend to do.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
Box2way <- ggpubr::ggboxplot(TwoWay_df, x = "Dept", y = "TradPed", color = "Stage", xlab = "Academic Department",
    ylab = "Students' Evaluations of Traditional Pedagogy", add = "jitter",
    title = "Course Evaluations as a Function of Department and Stage in Transition")
Box2way
```

#### Evaluate statistical assumptions.

**Is the dependent variable normally distributed at all levels of the combinations of the levels within the grouping variables?**

I'll start with an inspection of skew and kurtosis for all combinations of the levels of the two grouping variables.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
psych::describeBy(TradPed ~ Stage + Dept, mat = TRUE, data = TwoWay_df, digits = 3, type = 1)
```

Following Kline's (2016) recommendations, skew for each combination of levels of the two IVs are < |3.0|.  Kurtosis for each combination of levels of the two IVs are < |10.0|.

The Shapiro-Wilk examines residuals from the ANOVA model. We can quickly/preliminarily run the two-way ANOVA. We do this to produce an object that holds the *model residuals.*
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
TwoWay_TradPed <- aov(TradPed ~ Stage * Dept, TwoWay_df)
summary(TwoWay_TradPed)
```
The *residuals()* function serves to extract the residuals. We can apply the model-baesd *shapiro.test()* function from base R to see if the model residuals are non-normally distributed.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
resid_TradPed <- residuals(TwoWay_TradPed)
shapiro.test(resid_TradPed)
```

A statistically significant Shapiro-Wilks' test of normality suggests that we violated the assumption $W = 0.949, p < 0.001$.

Let's plot the residuals
```{r}
hist(resid_TradPed)
```
The histogram does look somewhat different (negatively skewed) from a normal distribution.
```{r}
qqnorm(resid_TradPed)
```

The dots stray from the expected diagonal; this also visualizes the non-normality of the data.

Summary so far:

>Factorial ANOVA assumes that the dependent variable is normally is distributed for all cells in the design. Although our analysis suggested skew and kurtosis were within the bounds considered to be normally distributed, the Shapiro-Wilk normality test (applied to the residuals from the factorial ANOVA model) suggested that the plotting of the residuals differed significantly from a normal distribution $W = 0.949, p < 0.001$.

**Are there outliers?**

Given the non-normality of the data, we can use the following procedure to see if there are outliers that could be transformed, truncated, or removed.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
library(tidyverse)
TwoWay_df %>%
    rstatix::identify_outliers(TradPed)
```

There are four outliers; none are extreme. Given that these are all on the low-side (of a negatively skewed distribution where most scores are higher), I feel it is important to retain them as they reflect more students' experiences. If this were for something other than a homework demonstration, I might also take a look at the case to see if there was evidence of inattention or something else.

**Are the variances of the dependent variable similar across the all combinations of the levels within the grouping variables?**

We can evaluate the homogeneity of variance test with Levene's test for the equality of error variances.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
rstatix::levene_test(TwoWay_df, TradPed ~ Dept * Stage)
```

Levene’s test has indicated a violation of the homogeneity of variance assumption $(F[5, 106] = 6.412, p < .001)$. This is not surprising. The boxplots shows some widely varying variances.

Do we have to stop?  If cell sizes are reasonably large (e.g., at least 15) and balanced (equal), ANOVA is a relatively robust to violations of normality.  Unfortunately, we don't have 15 in all cells AND our cells are unequal AND this was not an experiment. So.....this probably isn't the best approach (but it'll work for a class demo).

>A 2 X 3 ANOVA was conducted to evaluate the effects of academic department (2 levels, CPY and ORG) and stage of transition (3 levels, stable, transitioning, resettled) on traditional pedagogy course evaluation ratings. 

>Factorial ANOVA assumes that the dependent variable is normally is distributed for all cells in the design. Although our analysis suggested skew and kurtosis were within the bounds considered to be normally distributed, the Shapiro-Wilk normality test (applied to the residuals from the factorial ANOVA model) suggested that the plotting of the residuals differed significantly from a normal distribution $W = 0.949, p < 0.001$. Further, Levene’s test has indicated a violation of the homogeneity of variance assumption $(F[5, 106] = 6.412, p < .001)$. Owing to a rather desperate need to provide a demonstration of the two-way ANOVA, I have decided to proceed and keep these violations in mind in the interpretation of results.

#### Conduct omnibus ANOVA (w effect size).

We can use the *rstatix::anova_test()* function.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
omnibus2w <- rstatix::anova_test(TwoWay_df, TradPed ~ Dept * Stage, type = "2", detailed = TRUE)
omnibus2w
```

Let's write the F strings from the above table:

* Department main effect:  $F(1, 106) = 11.395, p = 0.001, \eta^2 = 0.097$
* Stage main effect:  $F(2, 106) = 10.070 , p < 0.001, \eta^2 = 0.160$
* Interaction effect:  $F(2, 106) = 4.904, p = 0.009, \eta^2 = 0.085$

So far we have statistically significant effects for the main and interaction effects. Here are the results so far:

>Computing sums of squares with a Type II approach, the results for the omnibus ANOVA indicated a significant effects for the main effect of department, $F(1, 106) = 11.395, p = 0.001, \eta^2 = 0.097$; the main effect for stage in transition, $F(2, 106) = 10.070, p < 0.001, \eta^2 = 0.160$; and the interaction effect, $F(2, 106) = 4.904, p = 0.009, \eta^2 = 0.085$. 

#### Conduct one set of follow-up tests; narrate your choice.

There are so many choices for following up a significant interaction effect. Regardless, we always follow a statistically significant interaction effect with an analysis of simple main effects. I think I am interested in the simple main effects for stage within department.  This means I will conduct one-way ANOVAS for CPY and ORG, separately. And, if either is significant, I will look for differences across the stages.

Although we could do something more complicated (like orthogonal contrast coding), given that those completing homework are often having early experiences with ANOVA, I will choose a more streamlined path by examining the the simple main effect of stage within department.

Functionally, this computes two one-way ANOVAs, comparing the three stages within each of the departments. If the result is statistically significant, we will need to follow-up with more testing. 

The *rstatix::anova_test* does not allow me to specify a control for Type I error. Therefore, if I wanted to do so, I would need to monitor it outside of the R package.  I *could* evaluate each of the *p* values for the two one-way ANOVAs at 0.025 (05/2). Rather than tracking Type I error at this level, I will wait and do so when I get to the pairwise comparisons that follow a statistically significant one-way ANOVA.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
TwoWay_df %>%
  dplyr::group_by(Dept)%>%
  rstatix::anova_test(TradPed ~ Stage)
```
Results suggest statistically significant differences in department across the stages within the CPY department, but not the ORG department:

* For CPY:  $F(2, 58) = 18.497, p < 0.001, \eta^2 = 0.389$
* For ORG: $F(2, 48) = 1.417, p = 0.252, \eta^2 = 0.056$

I would write up this stage of the analysis this way:

>To explore the significant interaction effect, we followed with a test of simple main effect of the stage in transition within the academic department. We began with separate one-way ANOVAs. Results indicated significant differences within the CPY deparmtent $(F[2, 58] = 18.497, p < 0.001, \eta^2 = 0.389)$, but not for the ORG department $(F[2, 48] = 1.417, p = 0.252, \eta^2 = 0.056)$.

Because there are three stages of transition, we need to followup with pairwise comparisons to see where the differences lie. Because I want to results from the significance tests to update the figure, I will save the output as an object.

Although, technically, we only needed to compare 3 pairwise tests, this test (and figure) will compute them all. The Holm's Sequential Bonferroni is a very reasonable approach (balancing Type I error with sensibility) and so I will use it to evaluate the six pairwise comparisons that will be produced.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
pwTRwiDP <- TwoWay_df %>%
    dplyr::group_by(Dept) %>%
    rstatix::emmeans_test(TradPed ~ Stage, p.adjust.method = "holm")
pwTRwiDP
```


Consistent with the significant one-way ANOVA for the ORG factor, there were non-significant differences between all pairs of stages.  Within the CPY student evaluations, there were statistically significant differences between stable and transition and stabled and resettled comparisons. Both comparisons favored the stable level.


Here'w how I would assemble the entire APA style results:

>A 2 X 3 ANOVA was conducted to evaluate the effects of academic department (2 levels, CPY and ORG) and stage of transition (3 levels, stable, transitioning, resettled) and  on traditional pedagogy course evaluation ratings. 

>Factorial ANOVA assumes that the dependent variable is normally is distributed for all cells in the design. Although our analysis suggested skew and kurtosis were within the bounds considered to be normally distributed, the Shapiro-Wilk normality test (applied to the residuals from the factorial ANOVA model) suggested that the plotting of the residuals differed significantly from a normal distribution $W = 0.949, p < 0.001$. Further, Levene’s test has indicated a violation of the homogeneity of variance assumption $(F[5, 106] = 6.412, p < .001)$. Owing to a rather desperate need to provide a demonstration of the two-way ANOVA, I have decided to proceed and keep these violations in mind in the interpretation of results.

>Computing sums of squares with a Type II approach, the results for the omnibus ANOVA indicated a significant effects for the main effect of department, $F(1, 106) = 11.395, p = 0.001, \eta^2 = 0.097$; the main effect for stage in transition, in transition $F(2, 106) = 10.07 , p < 0.001, \eta^2 = 0.160$, and the interaction effect, $F(2, 106) = 4.904, p = 0.009, \eta^2 = 0.085$. 

> To explore the significant interaction effect, we followed with a test of simple main effect of the stage in transition within the academic department. We began with separate one-way ANOVAs. Results indicated significant differences within the CPY deparmtent $(F[2, 58] = 18.497	, p < 0.001, \eta^2 = 0.389)$, but not for the ORG department $(F[2, 48] = 1.417, p = 0.252, \eta^2 = 0.056)$.

>We followed the significant one-way ANOVAs with pairwise comparisons between the groups using the estimated marginal means. We specified the Holm's sequential Bonferroni for managing Type I error. For CPY students, comparisons  between the stable and transition $(t[106] = 4.997, p < 0.001)$ and stable and resettled $(t[106] = 2.893, p = 0.005)$ stages were statistically significantly different. Cell means, marginal means, and standard deviations are presented in Table 1; results are illustrated in Figure 1.

#### Describe approach for managing Type I error.

I managed Type I error with the Holm's sequential Bonferroni. The Holm's is less conservative than the traditional Bonferroni because it adjusts the thresshold for statistical significance in a stepwise manner that takes into consideration the rank order of the *p* values and the number of comparisons made.

#### APA style results with table(s) and figure.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
apaTables::apa.2way.table(Dept, Stage, TradPed, data = TwoWay_df, filename = "2Way.doc", table.number = 1, show.marginal.means = TRUE, landscape = TRUE)
```

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
pwTRwiDP <- pwTRwiDP %>%
    rstatix::add_xy_position(x = "Dept")  #x should be whatever the variable was used in the group_by argument 
Box2way <- Box2way + ggpubr::stat_pvalue_manual(pwTRwiDP, label = "p.adj.signif", tip.length = 0.02, hide.ns = TRUE, y.position = c(5.3, 5.5))
Box2way
```
#### Conduct power analyses to determine the power of the current study and a recommended sample size.

The *pwr.2way()* and *ss.2way()* functions require the following:

* **a** number of groups in Factor A
* **b** number of groups in Factor B
* **alpha** significant level (Type I error probability)
* **beta** Type II error probability (Power = 1 - beta; traditionally set at .1 or .2)
* **f.A** the *f* effect size of Factor A 
* **f.B** the *f* effect size of Factor B
* **B** Iteration times, default is 100 

We need to convert our effect size ($\eta^2$) for the *interaction* to $f$ effect size (this is not the same as the *F* test). The *effectsize* package has a series of converters. We can use the *eta2_to_f()* function. 

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
effectsize::eta2_to_f(0.097) #FactorA -- Dept
effectsize::eta2_to_f(0.160) #Factor B -- Stage
effectsize::eta2_to_f(0.085) #interaction
```

The size.A and size.B are the sample size per group within the factor. Because ours differ, i divided the N by the number of groups.
```{r}
112/2
112/3
112/6
``` 

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
pwr2::pwr.2way(a = 2, b = 3, alpha = 0.05, size.A = 56, size.B = 37, f.A = 0.3277495, f.B = 0.4364358)
```
At 100% (Dept), 100 (Stage), and 100% (interaction), our power to detect statistically significant main and interaction effects was strong

I will use a different function to estimate what sample size would be sufficiently powerful. In this syntax:

* beta is the Type II error probability (Power = 1-beta); usually set at 80
* B is the iteration times, the default is 100

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
pwr2::ss.2way(a = 2, b = 3, alpha = 0.05, beta = 0.8, f.A = 0.3277495, f.B = 0.4364358, B = 100)
```
```{r}
18*3
```
This recommends a sample size of 54; 18 in each group.

### Hand Calculations

Before we continue: 

>You may notice that the results from the hand calculation are slightly different from the results I will obtain with the R packages. This is because the formula we have used for the hand-calculations utilizes an  approach to calculating the sums of squares that presumes that we have a balanced design (i.e., that the cell sizes are equal). When cell sizes are unequal (i.e., an unbalanced design) the Type II package in *rstatix::anova_test* will produce different result.

> Should we be concerned? No (and yes). My purpose in teaching hand calculations is for creating a conceptual overview of what is occurring in ANOVA models. If this lesson was a deeper exploration into the inner workings of ANOVA, we would take more time to understand what is occurring. My goal is to provide you with enough of an introduction to ANOVA that you would be able to explore further which sums of squares type would be most appropriate for your unique ANOVA model.

#### Calculate sums of squares total (SST) for the omnibus ANOVA. Steps in this calculation must include calculating a grand mean and creating variables representing the mean deviation and mean deviation squared.

Here is the formula I will use for calculating the sums of squares total:  $$SS_{T}= \sum (x_{i}-\bar{x}_{grand})^{2}$$

I will use *psych::describe()* to obtain the overall mean:

```{r}
psych::describe(TwoWay_df)
```

The overall (grand) mean is 4.06.

I will create a variable that represents the mean deviation:

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
TwoWay_df <- TwoWay_df %>%
  dplyr::mutate(m_dev = TradPed - 4.06)

head(TwoWay_df)
```

Now I will square the mean deviation:

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
TwoWay_df <- TwoWay_df %>%
    mutate(m_devSQ = m_dev^2)
head(TwoWay_df)
```

SST is the sum of the mean deviation squared values:

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
SST <- sum(TwoWay_df$m_devSQ, na.rm=TRUE)
SST
```
Our sums of squares total is 83.0332


#### Calculate the sums of squares for the model (SSM) for the omnibus ANOVA. A necessary step in this equation is to calculate group means for all combinations of the levels in the factorial design.

Here is the formula for calculating SSM:  $$SS_{M}= \sum n_{k}(\bar{x}_{k}-\bar{x}_{grand})^{2}$$

The formula indicates that we need:

* *n* (sample size for each group)
* Group means
* Grand mean (earlier we learned it was 4.06)

I will obtain group means and $n$s with *psych::desribeBy*.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
psych::describeBy(TradPed ~ Dept + Stage, mat = TRUE, data = TwoWay_df, digits = 3)
```

To calculate it:
 
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
SSM <- 25 * (4.832 - 4.06)^2 + 25 * (3.864 - 4.06)^2 + 26 * (3.769 - 4.06)^2 +
    15 * (3.560 - 4.06)^2 + 10 * (4.010 - 4.06)^2 + 11 * (4.145 - 4.06)^2
SSM
```
Sums of squares for the model is 21.91618.

#### Calculate the sums of squares residual (SSR) for the omnibus ANOVA. A necessary step in this equation is to calculate the variance for each group.

I will use the following formula to calculate SSR: $$SS_{R}= s_{group1}^{2}(n-1) + s_{group2}^{2}(n-1) + s_{group3}^{2}(n-1) + s_{group4}^{2}(n-1) + s_{group5}^{2}(n-1) + s_{group6}^{2}(n-1))$$

This requires:

* *n* (sample size for each group)
* group variance (I can square the standard deviation for each group)

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
SSR <- ((0.236^2)*(25-1))+ ((0.582^2)*(25-1)) + ((0.878^2)*(26-1)) + ((1.338^2)*(15-1)) + ((0.578^2)*(10-1)) + ((0.658^2)*(11-1))
SSR
```
Our sums of squares for the residual is 61.13799.

#### Calculate sums of squares model (SSM) for each of the factors in the model.

**SSM for the Department main effect:**

Reminder of the formula: $SS_{a:Dept}= \sum n_{k}(\bar{x}_{k}-\bar{x}_{grand})^{2}$

Earlier I learned the grand mean = 4.06

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
psych::describeBy(TradPed ~ Dept, mat=TRUE, data = TwoWay_df, digits=3)
```
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
SSM_dept <- 61 * (4.244 - 4.06)^2 + 51 * (3.835 - 4.06)^2
SSM_dept
```
Sums of squares model for the department factor is 4.647091.

**SSM for the Stage main effect:**

Reminder of the formula: $SS_{a:Stage}= \sum n_{k}(\bar{x}_{k}-\bar{x}_{grand})^{2}$

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
psych::describeBy(TradPed ~ Stage, mat=TRUE, data = TwoWay_df, digits=3)
```

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
SSM_stage <- 50 * (4.348 - 4.06)^2 + 42 * (3.693 - 4.06)^2 + 32 * (4.081 - 4.06)^2
SSM_stage
```
Sums of squares model for the stage factor is 9.81825

**SSM for the Department x Stage interaction term:**

I can calculate the SSM for the interaction term with this formula:  $SS_{axb} = SS_M - (SS_a + SS_b)$


```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
SSM_int <- 21.91618 - (4.647091 + 9.81825)
SSM_int
```

#### Create a source table that includes the sums of squares, degrees of freedom, mean squares, *F* values, and *F* critical values. 

It is easiest for me when I put these in a table.

|Summary ANOVA for TradPed as a Function of Dept & Stage
|:-------------------------------------------------------|

|Source    |SS       |df         |$MS = \frac{SS}{df}$ |$F = \frac{MS_{source}}{MS_{resid}}$ |$F_{CV}$|
|:---------|:--------|:----------|:------|:------|:------|
|Model     |21.916   |5          |4.383  |7.596  |2.300  |
|a:Dept    |4.647    |1          |4.647  |8.054  |3.931  |
|b:Stage   |9.818    |2          |4.909  |8.508  |3.082  |
|aXb       |7.451    |2          |3.726  |6.458  |3.082  |
|Residual  |61.138   |106        |0.577  |       |       |
|Total     |83.033   |           |       |       |       |

Main effect for department: $F(1, 106) = 8.054, p < 0.05$ 
Main effect for stage: $F(2, 106) = 8.508, p < 0.05$
Interaction effect: $F(2, 106) = 6.458, p < 0.05$

You may notice that these calculations don't exactly follow the rules of the lecture.  For example, The "model and "residual" should equal the total. I believe this is because there are different cell sizes which causes an unbalanced design and throws off the otherwise perfect calculations. This issue of unbalanced design is an important one in ANOVA.

Checking to see if my sums of squares a, b, and axb equal the SSM; and that SSM + SSR = SST.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
21.916 + 61.138
(4.647 + 9.818 + 7.451) + 61.138
4.647 + 9.818 + 7.451
```
Below are the calculations for the mean square values:
```{r}
21.916 /5
4.647/1
9.818/2
7.451/2
61.138/106
```
Below are the calculations for the *F* tests:

```{r}
4.383/0.577
4.647/0.577
4.909/0.577
3.726/0.577
```
Looking up the *F* critical values (requires alpha level and degrees of freedom for the numerator and denominator [model and residual]):

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
qf(0.05, 5, 106, lower.tail = FALSE)  #omnibus
qf(0.05, 1, 106, lower.tail = FALSE)  #Dept main effect
qf(0.05, 2, 106, lower.tail = FALSE)  #Stage main effect
qf(0.05, 2, 106, lower.tail = FALSE)  #interaction term
```

#### Are the *F*-tests for the main and interaction effects statistically significant? Why or why not? 

In the hand calculations, the main and interaction effects are significant when the *F* value exceeds the *F* critical value. All three are.

#### Calculate and interpret the $\eta^2$ effect sizes for the main and interaction effects. 

The formula for eta squared is:

$$\eta ^{2}=\frac{SS_{M}}{SS_{T}}$$

The values of .01, .06, and .14 are considered small, medium, and large in ANOVA models.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
4.647/83.033 #eta squared for department main effect
9.818/83.033 #eta squared for stage main effect
7.451/83.033 #eta squared for interaction effect
```

The $\eta ^{2}$ values are 0.056 (medium), 0.118 (medium-to-large), and 0.090 (medium-to-large) for the department, stage, and interaction effects, respectively. 

#### Assemble the results into their statistical strings.

Main effect for department: $F(1, 106) = 8.054, p < 0.05, \eta ^{2} = 0.056$ 
Main effect for stage: $F(2, 106) = 8.508, p < 0.05, \eta ^{2} = 0.118$
Interaction effect: $FF(2, 106) = 6.458, p < 0.05, \eta ^{2} = 0.090$