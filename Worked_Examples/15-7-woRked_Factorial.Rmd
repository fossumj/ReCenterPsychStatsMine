## Homeworked Example

[Screencast Link]()

*If you wanted to use this example and dataset as a basis for a homework assignment, you could create a different subset of data. I worked the example for students taking the ANOVA class. You could choose multivariate or psychometrics. You could also choose a different dependent variable. I chose the traditional pedagogy subscale. Two other subscales include socially responsive pedagogy and valued by the student.*

### Working the Problem with R and R Packages

#### Narrate the research vignette, describing the IV and DV. Miniminally, the data should allow the analysis of a 2 x 3 (or 3 X 2) design. At least one of the problems you work should have a significant interaction effect so that follow-up is required.

I want to ask the question, do course evaluation ratings for the traditional pedagogy dimension differ for students in the ANOVA class as a function of:

* stage in the revision (Stable, Transitioning, Resettled), and
* Department (CPY vs ORG) 

#### Simulate (or import) and format data.

```{r}
big <- readRDS("ReC.rds")
```

Let's first create the "Stage" variable that represents the three levels of transition.

First I will map the years to the three levels (factors).

```{r}
big$Stage <- plyr::mapvalues(big$Year, from = c(2017, 2018, 2019, 2020, 2021), to = c("Stable", "Transition", "Transition", "Resettled", "Resettled"))
```

Then check the structure.
```{r}
str(big$Stage)
```
R is reading the variable as a character, so I need to make it to be an ordered factor.

```{r}
big$Stage <- factor(big$Stage, levels = c("Stable", "Transition", "Resettled"))
```

Let's check the structure again:

```{r}
str(big$Stage)
```
The TradPed (traditional pedagogy) variable is an average of the items on that scale. I will first create that variable.

```{r}
#Creates a list of the variables that belong to that scale
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')

#Calculates a mean if at least 75% of the items are non-missing; adjusts the calculating when there is missingness
big$TradPed <- sjstats::mean_n(big[, TradPed_vars], .75)

#if the scoring script won't run, try this one:
#big$TradPed <- sjstats::mean_n(big[, ..TradPed_vars], .75)
```

Each student in the dataset could contribute up to three course evaluations (i.e., one each for ANOVA, multivariate, psychometrics). Including all three would introduce *dependency* into the dataset and violate the assumption of independence. With our variables properly formatted let's create a subset with just the students who took ANOVA. 
```{r}
TwoWay_df <- subset(big, Course == "ANOVA") 
```

Next, let's trim it to just the variables we need.
```{r}
TwoWay_df <-(dplyr::select (TwoWay_df, Stage, Dept, TradPed))
```

Although we would handle missing data more carefully in a "real study," I will delete all cases with any missingness. This will prevent problems in the hand-calculations section, later (and keep the two sets of results more similar).

```{r}
df <- na.omit(TwoWay_df)
```

Before we continue, this data has a hiccup that makes it less than ideal for a 2 x 3 ANOVA. In 2017 everyone enrolled in the CPY section of the course. That is, there was no distinction between CPY and ORG students.  In this dataset I do not have another variable with three levels.  I will recode some data which MAKES THE STORY UNTRUE, but will allow me to demo 2-way ANOVA (sighhhh). For your homework, you are very welcome to engage in such practices (it's actually good for learning!) however, we would never do so in the analysis of real data. 

```{r}
TwoWay_df <- na.omit(TwoWay_df) #the next operation required non-missing data
TwoWay_df[TwoWay_df$Stage == "Stable" & TwoWay_df$TradPed < 4.3, "Dept"]<- "ORG"
```


Although the homework assignment doesn't require it, I think it's useful to create a figure that shows what I intend to do.

```{r}
Box2way<- ggpubr::ggboxplot(TwoWay_df, x = "Dept", y = "TradPed", color = "Stage", xlab = "Academic Department",
    ylab = "Students' Evaluations of Traditional Pedagogy", add = "jitter",
    title = "Course Evaluations as a Function of Department and Stage in Transition")
Box2way
```


#### Evaluate statistical assumptions.

**Is the dependent variable normally disributed at all levels of the combinations of the levels within the grouping variables?**

I'll start with an inspection of skew and kurtosis for all combinations of the levels of the two grouping variables.

```{r}
psych::describeBy(TradPed ~ Stage + Dept, mat = TRUE, data = TwoWay_df, digits = 3, type = 1)
```



Following Kline's (2016) recommendations, skew for each combination of levels of the two IVs are < |3.0|.  Kurtosis for each combination of levels of the two IVs are < |10.0|.

The Shapiro-Wilk examines residuals from the ANOVA model. We can quickly/preliminarily run the two-way ANOVA. We do this to produce an object that holds the *model residuals.*

```{r}
TwoWay_TradPed <- aov(TradPed ~ Stage * Dept, TwoWay_df)
summary(TwoWay_TradPed)
```
The *residuals()* function serves to extract the residuals. We can apply the model-baesd *shapiro.test()* function from base R to see if the model residuals are non-normally distributed.
```{r}
resid_TradPed <- residuals(TwoWay_TradPed)
shapiro.test(resid_TradPed)
```

A statistically significant Shapiro-Wilks' test of normality suggests that we violated the assumption $W = 0.942, p = 0.001$.

Let's plot the residuals

```{r}
hist(resid_TradPed)
```
The histogram does look somewhat different (negatively skewed) from a normal distribution.

```{r}
qqnorm(resid_TradPed)
```

The dots stray from the expected diagonal; this also visualizes the non-normality of the data.

Summary so far:

>Factorial ANOVA assumes that the dependent variable is normally is distributed for all cells in the design. Although our analysis suggested skew and kurtosis were within the bounds considered to be normally distributed, the Shapiro-Wilk normality test (applied to the residuals from the factorial ANOVA model) suggested that the plotting of the residuals differed significantly from a normal distribution $W = 0.942, p = 0.001$.

**Are there outliers?**

Given the non-normality of the data, we can use the following procedure to see if there are outliers that could be transformed, truncated, or removed.

```{r}
library(tidyverse)
TwoWay_df %>%
    rstatix::identify_outliers(TradPed)
```

There are four outliers; none are extreme. Given that these are all on the low-side (of a negatively skewed distribution where most scores are higher), I feel it is important to retain them as they reflect more students' experiences. If this were for something other than a homework demonstration, I might also take a look at the case to see if there was evidence of inattention or something else.

**Are the variances of the dependent variable similar across the all combinations of the levels within the grouping variables?**

We can evaluate the homogeneity of variance test with Levene's test for the equality of error variances.

```{r}
rstatix::levene_test(TwoWay_df, TradPed ~ Dept * Stage)
```

Levene’s test has indicated a violation of the homogeneity of variance assumption $(F[5, 106] = 4.5489, p < .001)$. This is not surprising. The boxplots shows some widely varying variances.

Do we have to stop?  If cell sizes are reasonably large (e.g., at least 15) and balanced (equal), ANOVA is a relatively robust to violations of normality.  Unfortunately, we don't have 15 in all cells AND our cells are unequal AND this was not an experiment. So.....this probably isn't the best approach (but it'll work for a class demo).

>A 2 X 3 ANOVA was conducted to evaluate the effects of academic department (2 levels, CPY and ORG) and stage of transition (3 levels, stable, transitioning, resettled) and  on traditional pedagogy course evaluation ratings. Factorial ANOVA assumes that the dependent variable is normally is distributed for all cells in the design. Although our analysis suggested skew and kurtosis were within the bounds considered to be normally distributed, the Shapiro-Wilk normality test (applied to the residuals from the factorial ANOVA model) suggested that the plotting of the residuals differed significantly from a normal distribution $W = 0.942, p = 0.001$. Further, Levene’s test has indicated a violation of the homogeneity of variance assumption $(F[5, 106] = 4.5489, p < .001)$. Owing to a rather desperate need to provide a demonstration of the two-way ANOVA, I have decided to proceed and keep these violations in mind in the interpretation of results.

#### Conduct omnibus ANOVA (w effect size).

We can use the *rstatix::anova_test()* function.

```{r}
omnibus2w <- rstatix::anova_test(TwoWay_df, TradPed ~ Dept * Stage, type = "2", detailed = TRUE)
omnibus2w
```

Let's write the F strings from the above table:

* Department main effect:  $F(1, 106) = 4.647, p = 0.033, \eta^2 = 0.042$
* Stage main effect:  $F(2, 106) = 3.616 , p = 0.030, \eta^2 = 0.064$
* Interaction effect:  $F(2, 106) = 4.567, p = 0.013, \eta^2 = 0.079$

So far we have statistically significant effects for the main and interaction effects. Here are the results so far:

>Computing sums of squares with a Type II approach, the results for the omnibus ANOVA indicated a significant effects for the main effect of department, $F(1, 106) = 4.647, p = 0.033, \eta^2 = 0.042$; the main effect for stage in transition, in transition $F(2, 106) = 3.616 , p = 0.030, \eta^2 = 0.064$, and the interaction effect, $F(2, 106) = 4.567, p = 0.013, \eta^2 = 0.079$.

#### Conduct one set of follow-up tests; narrate your choice.

There are so many choices for following up a significant interaction effect. Regardless, we always follow a statistically significant interaction effect with an analysis of simple main effects. I think I am interested in the simple main effects for stage within department.  This means I will conduct one-way ANOVAS for CPY and ORG, separately. And, if either is significant, I will look for differences across the stages.

Although we could do something more complicated (like orthogonal contrast coding), given that those completing homework are often having early experiences with ANOVA, I will choose a more streamlined path by examining the the simple main effect of stage within department.

Functionally, this computes three one-way ANOVAs, comparing the three stages within each of the departments within each of the three stages of transition.  Functionally, this will produce two one-way ANOVAs. If the result is statistically significant, we will need to follow-up with more testing. 

The *rstatix::anova_test* does not allow me to specify a control for Type I error. Therefore, if I wanted to do so, I would need to monitor it outside of the R package.  I could evaluate each of the *p* values for the two one-way ANOVAs at 0.025 (05/2). Rather than tracking Type I error at this level, I will wait and do so when I get to the pairwise comparisons that follow a statistically significant one-way ANOVA.

```{r}
TwoWay_df %>%
  dplyr::group_by(Dept)%>%
  rstatix::anova_test(TradPed ~ Stage)
```
Results suggest statistically significant differences in department across the stages within the CPY department, but not the ORG department:

* For CPY:  $F(2, 69) = 9.548, p < 0.001, \eta^2 = 0.217$
* For ORG: $F(2, 37) = 0.668, p = 0.519, \eta^2 = 0.315$

I would write up this stage of the analysis this way:

> To explore the significant interaction effect, we followed with a test of simple main effect of the stage in transition within the academic department. We began with separate one-way ANOVAs. Results indicated significant differences within the CPY deparmtent ($F[2, 69] = 9.548, p < 0.001, \eta^2 = 0.217$), but not for the ORG department ($F[2, 37] = 0.668, p = 0.519, \eta^2 = 0.315$).

Because there are three stages of transition, we need to followup with pairwise comparisons to see where the differences lie. Because I want to results from the significance tests to update the figure, I will save the output as an object.

Although we only needed to compare 3 pairwise tests, this test (and figure) will compute them all. The Holm's Sequential Bonferroni is a very reasonable approach (balancing Type I error with sensibility) and so I will use it to evaluate the six pairwise comparisons that will be produced.

```{r}
pwTRwiDP <- TwoWay_df %>%
    dplyr::group_by(Dept) %>%
    rstatix::emmeans_test(TradPed ~ Stage, p.adjust.method = "holm")
pwTRwiDP
```


Consistent with the significant one-way ANOVA for the ORG factor, there were non-significant differences between all pairs of stages.  Within the CPY student evaluations, there were statistically significant differences between stable and resettled. Had we not controlled for Type I error, there would have also been significant differences between transition and resettled.

Let's update our figure with a representation of these pairwise comparisons.

Here'w how I would assemble the entire APA style results:

>A 2 X 3 ANOVA was conducted to evaluate the effects of academic department (2 levels, CPY and ORG) and stage of transition (3 levels, stable, transitioning, resettled) and  on traditional pedagogy course evaluation ratings. Factorial ANOVA assumes that the dependent variable is normally is distributed for all cells in the design. Although our analysis suggested skew and kurtosis were within the bounds considered to be normally distributed, the Shapiro-Wilk normality test (applied to the residuals from the factorial ANOVA model) suggested that the plotting of the residuals differed significantly from a normal distribution $W = 0.942, p = 0.001$. Further, Levene’s test has indicated a violation of the homogeneity of variance assumption $(F[5, 106] = 4.5489, p < .001)$. Owing to a rather desperate need to provide a demonstration of the two-way ANOVA, I have decided to proceed and keep these violations in mind in the interpretation of results.

>Computing sums of squares with a Type II approach, the results for the omnibus ANOVA indicated a significant effects for the main effect of department, $F(1, 106) = 4.647, p = 0.033, \eta^2 = 0.042$; the main effect for stage in transition, in transition $F(2, 106) = 3.616 , p = 0.030, \eta^2 = 0.064$, and the interaction effect, $F(2, 106) = 4.567, p = 0.013, \eta^2 = 0.079$.

>To explore the significant interaction effect, we followed with a test of simple main effect of the stage in transition within the academic department. We began with separate one-way ANOVAs. Results indicated significant differences within the CPY deparmtent ($F[2, 69] = 9.548, p < 0.001, \eta^2 = 0.217$), but not for the ORG department ($F[2, 37] = 0.668, p = 0.519, \eta^2 = 0.315$).

>We followed the significant one-way ANOVA with pairwise comparisons between the groups using the estimated marginal means. We specified the Holm's sequential Bonferroni for managing Type I error. Only the comparison between the stable and resettled conditions within CPY students were statistically significantly different $t(106) = 3.6167765, p = 0.001$. Cell and marginal means and standard deviations are presented in Table 1; results are illustrated in Figure 1.

#### Describe approach for managing Type I error.

I managed Type I error with the Holm's sequential Bonferroni. The Holm's is less conservative than the traditional Bonferroni because it adjusts the thresshold for statistical significance in a stepwise manner that takes into consideration the rank order of the *p* values and the number of comparisons made.

#### APA style results with table(s) and figure.

```{r}
apaTables::apa.2way.table(Dept, Stage, TradPed, data = TwoWay_df, filename = "2Way.doc", table.number = 1, show.marginal.means = TRUE, landscape = TRUE)
```

```{r}
pwTRwiDP <- pwTRwiDP %>%
    rstatix::add_xy_position(x = "Dept")  #x should be whatever the variable was used in the group_by argument 
Box2way <- Box2way + ggpubr::stat_pvalue_manual(pwTRwiDP, label = "p.adj.signif", tip.length = 0.02, hide.ns = TRUE, y.position = c(5.3))
Box2way
```
#### Conduct power analyses to determine the power of the current study and a recommended sample size.

The *pwr.2way()* and *ss.2way()* functions require the following:

* **a** number of groups in Factor A
* **b** number of groups in Factor B
* **alpha** significant level (Type I error probability)
* **beta** Type II error probability (Power = 1 - beta; traditionally set at .1 or .2)
* **f.A** the *f* effect size of Factor A 
* **f.B** the *f* effect size of Factor B
* **B** Iteration times, default is 100 

We need to convert our effect size ($\eta^2$) for the *interaction* to $f$ effect size (this is not the same as the *F* test). The *effectsize* package has a series of converters. We can use the *eta2_to_f()* function. 

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
effectsize::eta2_to_f(0.042) #FactorA -- Dept
effectsize::eta2_to_f(0.064) #Factor B -- Stage
effectsize::eta2_to_f(0.013) #interaction
```

The size.A and size.B are the sample size per group within the factor. Because ours differ, i divided the N by the number of groups.
```{r}
12+24+36+9+20+11
(12+24+36+9+20+11)/3
(12+24+36+9+20+11)/2
``` 

```{r}
pwr2::pwr.2way(a = 2, b = 3, alpha = 0.05, size.A = 37, size.B = 56, f.A = 0.042, f.B = 0.063)
```
At 10% (Dept), 16% (Stage), and 10% (interaction), our power to detect statistically significant main and interaction effects was low.

I will use a different function to estimate what sample size would be sufficiently powerful. In this syntax:

* beta is the Type II error probability (Power = 1-beta); usually set at 80
* B is the iteration times, the default is 100

```{r}
pwr2::ss.2way(a = 2, b = 3, alpha = 0.05, beta = 0.8, f.A = 0.042, f.B = 0.063, B = 100)
```
This recommends a sample size of 606; 100 in each group.

### Hand Calculations

#### Calculate sums of squares total (SST) for the omnibus ANOVA. Steps in this calculation must include calculating a grand mean and creating variables representing the mean deviation and mean deviation squared.

Here is the formula I will use for calculating the sums of squares total:  $$SS_{T}= \sum (x_{i}-\bar{x}_{grand})^{2}$$

I will use *psych::describe()* to obtain the overall mean:

```{r}
psych::describe(TwoWay_df)
```





#### Calculate the sums of squares for the model (SSM) for the omnibus ANOVA. A necessary step in this equation is to calculate group means for all combinations of the levels in the factorial design.

#### Calculate the sums of squares residual (SSR) for the omnibus ANOVA. A necessary step in this equation is to calculate the variance for each group.

#### Calculate sums of squares total (SST) for each of the factors in the model.

#### Calculate the sums of squares for the model (SSM) for each of the factors in the model. 

#### Calculate the sums of squares residual (SSR) for each of the factors in the model.

#### Calculate the mean square models, mean square residuals, and *F*-tests for the main and interaction effects. 

#### What are the degrees of freedom for your numerator and denominator for the main effects and interaction effect?

#### Locate the test critical values for your main effects and interaction effect.

#### Are the *F*-tests for the main and interaction effects statistically significant? Why or why not? 

#### Calculate and interpret the $\eta^2$ effect sizes for the main and interaction effects. 

#### Assemble the results into a statistical string.